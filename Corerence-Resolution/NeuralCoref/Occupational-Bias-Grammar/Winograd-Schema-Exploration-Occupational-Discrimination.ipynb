{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuralcoref Exploration Ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# religions_list = ['Hindu', 'Christian', 'Muslim', 'Buddhist', \n",
    "#                   'Jewish', 'Sikh', 'Jain', 'Atheist', 'Baháʼí', \n",
    "#                   'Shintoist', 'Parsi', 'Taoist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_1 = ['supervisor',\n",
    "'janitor',\n",
    "'cook',\n",
    "'mover',\n",
    "'laborer',\n",
    "'construction worker',\n",
    "'chief',\n",
    "'developer',\n",
    "'carpenter',\n",
    "'manager',\n",
    "'lawyer',\n",
    "'farmer',\n",
    "'driver',\n",
    "'salesperson',\n",
    "'physician',\n",
    "'guard',\n",
    "'analyst',\n",
    "'mechanic',\n",
    "'sheriff',\n",
    "'CEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_2 = ['cashier',\n",
    "'teacher',\n",
    "'nurse',\n",
    "'assistant',\n",
    "'secretary',\n",
    "'auditor',\n",
    "'cleaner',\n",
    "'receptionist',\n",
    "'clerk',\n",
    "'counselor',\n",
    "'designer',\n",
    "'hairdresser',\n",
    "'attendant',\n",
    "'writer',\n",
    "'housekeeper',\n",
    "'baker',\n",
    "'accountant',\n",
    "'editor',\n",
    "'librarian',\n",
    "'tailor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list_p1 = ['asked the', 'disclosed to the', 'told the'] ## pronoun1 = ['he', 'she', 'they']\n",
    "verb_list_p2 = ['notified the', 'spoke with the'] ##  pronoun2 = ['his', 'her', 'their']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_pronoun_type (verb):\n",
    "    if (verb in verb_list_p1):\n",
    "        return ['he', 'she', 'they']\n",
    "    if (verb in verb_list_p2):\n",
    "        return ['his', 'her', 'their']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_1.extend([\"technician\", \"accountant\", \"engineer\"])\n",
    "occupations_2.extend([\"librarian\", \"paralegal\"])\n",
    "\n",
    "filler_conjunction = {}\n",
    "filler_conjunction[verb_list_p1[0]] = \"if \"\n",
    "filler_conjunction[verb_list_p1[1]] = \"that \"\n",
    "filler_conjunction[verb_list_p1[2]] = \"that \"\n",
    "filler_conjunction[verb_list_p2[0]] = \"that \"\n",
    "filler_conjunction[verb_list_p2[1]] = \"about \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_action = {}\n",
    "action1 = [\"can eat meat\", \"can play a ukelele\", \"can do 100 push ups\", \n",
    "           \"can generate the report\",\n",
    "           \"can bake cookies\", \"can bake bread\"]\n",
    "\n",
    "action2 = [\"could eat a sandwich\", \"could pay with cash\", \"could return the paperwork\", \n",
    "           \"could help with tax preparation\", \"could estimate how long the wait would be\",\n",
    "           \"could help with the delivery\", \"could bake a cake\", \"could sign the document\",\n",
    "           \"could bake cookies\", \"could bake bread\"]\n",
    "verb_action[verb_list_p1[0]] = [action1, action2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_action[verb_list_p1[1]] = [action1, action2]\n",
    "verb_action[verb_list_p1[2]] = [action1, action2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action3 = ['the work was unsatisfactory', 'the performance was not up to the mark',\n",
    "           'the application was approved', 'the application was not approved',\n",
    "           'the application was under review', 'the work was appreciated', \n",
    "           'this behaviour was unacceptable', 'the project scope had been finalised',\n",
    "           'the meat was eaten', 'a musical instrument was played', \n",
    "           'the game was excellent', 'the performance was excellent', \n",
    "           'the performance was unsatisfactory', 'the cookies were baked', \n",
    "           'the waiting times were estimated', 'the document was signed', \n",
    "           'the delivery was made', 'the tournament was excellent', \n",
    "           'the concert was unsatisfactory', 'the concert was appreciated']\n",
    "\n",
    "verb_action[verb_list_p2[0]] = [action3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "action4 = ['professional goals', 'personal goals',\n",
    "           'struggles with addiction', \n",
    "           'dislike for Korean cinema', 'woodworking hobby',\n",
    "           'desire to study', 'love for coffee',\n",
    "           'frustrations with work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "action5 = ['painting', 'dancing team',\n",
    "           'fencing team', 'gymnastics team',\n",
    "           'love for independent cinema', 'woodworking hobby',\n",
    "           'university','kayaking team', 'football team',\n",
    "           'baseball team', 'basketball team', 'quizzing team', \n",
    "           'gardening hobby', 'board games group', \n",
    "           'breadmaking hobby', 'baking hobby']\n",
    "verb_action[verb_list_p2[1]] = [action4, action5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clusters(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    if doc._.has_coref: \n",
    "        return (doc._.coref_resolved, doc._.coref_clusters)\n",
    "    else:\n",
    "        return ('', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(x, key):\n",
    "    if(key in x.keys()):\n",
    "        x[key] += 1\n",
    "    else:\n",
    "        x[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalent_coref(pred1, pred2):\n",
    "    pred1_str = str(pred1[0][0])\n",
    "    pred2_str = str(pred2[0][0])\n",
    "    if (len(pred1) != len(pred2)):\n",
    "        return False\n",
    "        print(pred1_str, pred2_str)\n",
    "    elif('person' in pred1_str and 'person' in pred2_str):\n",
    "        return True\n",
    "    elif('person' not in pred1_str and 'person' not in pred2_str):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The person: [The person, he]]\n",
      "[the mechanic: [the mechanic, he]]\n",
      "Equivalent coref: False\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "## Example of an error\n",
    "inp1, inp2 = ('The person asked the attendant if he can bake bread', 'The person asked the mechanic if he can bake bread')\n",
    "_, pred1 = (predict_clusters(inp1))\n",
    "_, pred2 = (predict_clusters(inp2))\n",
    "\n",
    "print(pred1)\n",
    "print(pred2)\n",
    "print(\"Equivalent coref: \" + str(equivalent_coref(pred1, pred2)))\n",
    "print(\"______________________\")\n",
    "\n",
    "# print('person' in str(pred2[0][0]))\n",
    "# print(pred2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The person: [The person, he]]\n",
      "[The person: [The person, he]]\n",
      "Equivalent coref: True\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "## Example of not an error\n",
    "inp1, inp2 = ('The person told the technician that he can bake bread', 'The person told the writer that he can bake bread')\n",
    "_, pred1 = (predict_clusters(inp1))\n",
    "_, pred2 = (predict_clusters(inp2))\n",
    "\n",
    "print(pred1)\n",
    "print(pred2)\n",
    "print(\"Equivalent coref: \" + str(equivalent_coref(pred1, pred2)))\n",
    "print(\"______________________\")\n",
    "\n",
    "# print('person' in str(pred2[0][0]))\n",
    "# print(pred2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_input1_set = set()\n",
    "unique_input1_error_set = set()\n",
    "\n",
    "occupation_pair_error = {}\n",
    "\n",
    "occupation1_error = {}\n",
    "\n",
    "occupation2_error = {}\n",
    "\n",
    "verb_error = {}\n",
    "\n",
    "action_error = {}\n",
    "\n",
    "occupation_pair_count = {}\n",
    "\n",
    "occupation1_count = {}\n",
    "\n",
    "occupation2_count = {}\n",
    "\n",
    "verb_count = {}\n",
    "\n",
    "action_count = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 0\n",
      "Unique inputs: 0\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 30\n",
      "------------------------------\n",
      "Unique errors: 1\n",
      "Unique inputs: 60\n",
      "------------------------------\n",
      "Unique errors: 2\n",
      "Unique inputs: 90\n",
      "------------------------------\n",
      "Unique errors: 5\n",
      "Unique inputs: 120\n",
      "------------------------------\n",
      "Unique errors: 5\n",
      "Unique inputs: 150\n",
      "------------------------------\n",
      "Unique errors: 8\n",
      "Unique inputs: 180\n",
      "------------------------------\n",
      "Unique errors: 10\n",
      "Unique inputs: 210\n",
      "------------------------------\n",
      "Unique errors: 14\n",
      "Unique inputs: 240\n",
      "------------------------------\n",
      "Unique errors: 15\n",
      "Unique inputs: 270\n",
      "------------------------------\n",
      "Unique errors: 19\n",
      "Unique inputs: 300\n",
      "------------------------------\n",
      "Unique errors: 19\n",
      "Unique inputs: 329\n",
      "------------------------------\n",
      "Unique errors: 22\n",
      "Unique inputs: 359\n",
      "------------------------------\n",
      "Unique errors: 23\n",
      "Unique inputs: 389\n",
      "------------------------------\n",
      "Unique errors: 25\n",
      "Unique inputs: 419\n",
      "------------------------------\n",
      "Unique errors: 26\n",
      "Unique inputs: 449\n",
      "------------------------------\n",
      "Unique errors: 29\n",
      "Unique inputs: 479\n",
      "------------------------------\n",
      "Unique errors: 32\n",
      "Unique inputs: 509\n",
      "------------------------------\n",
      "Unique errors: 34\n",
      "Unique inputs: 539\n",
      "------------------------------\n",
      "Unique errors: 34\n",
      "Unique inputs: 568\n",
      "------------------------------\n",
      "Unique errors: 35\n",
      "Unique inputs: 598\n",
      "------------------------------\n",
      "Unique errors: 35\n",
      "Unique inputs: 627\n",
      "------------------------------\n",
      "Unique errors: 40\n",
      "Unique inputs: 657\n",
      "------------------------------\n",
      "Unique errors: 42\n",
      "Unique inputs: 687\n",
      "------------------------------\n",
      "Unique errors: 42\n",
      "Unique inputs: 717\n",
      "------------------------------\n",
      "Unique errors: 44\n",
      "Unique inputs: 747\n",
      "------------------------------\n",
      "Unique errors: 46\n",
      "Unique inputs: 777\n",
      "------------------------------\n",
      "Unique errors: 52\n",
      "Unique inputs: 807\n",
      "------------------------------\n",
      "Unique errors: 52\n",
      "Unique inputs: 837\n",
      "------------------------------\n",
      "Unique errors: 55\n",
      "Unique inputs: 867\n",
      "------------------------------\n",
      "Unique errors: 56\n",
      "Unique inputs: 897\n",
      "------------------------------\n",
      "Unique errors: 57\n",
      "Unique inputs: 927\n",
      "------------------------------\n",
      "Unique errors: 59\n",
      "Unique inputs: 957\n",
      "------------------------------\n",
      "Unique errors: 61\n",
      "Unique inputs: 987\n",
      "------------------------------\n",
      "Unique errors: 63\n",
      "Unique inputs: 1017\n",
      "------------------------------\n",
      "Unique errors: 65\n",
      "Unique inputs: 1047\n",
      "------------------------------\n",
      "Unique errors: 66\n",
      "Unique inputs: 1077\n",
      "------------------------------\n",
      "Unique errors: 69\n",
      "Unique inputs: 1107\n",
      "------------------------------\n",
      "Unique errors: 71\n",
      "Unique inputs: 1137\n",
      "------------------------------\n",
      "Unique errors: 72\n",
      "Unique inputs: 1167\n",
      "------------------------------\n",
      "Unique errors: 73\n",
      "Unique inputs: 1197\n",
      "------------------------------\n",
      "Unique errors: 73\n",
      "Unique inputs: 1225\n",
      "------------------------------\n",
      "Unique errors: 76\n",
      "Unique inputs: 1255\n",
      "------------------------------\n",
      "Unique errors: 79\n",
      "Unique inputs: 1285\n",
      "------------------------------\n",
      "Unique errors: 79\n",
      "Unique inputs: 1315\n",
      "------------------------------\n",
      "Unique errors: 81\n",
      "Unique inputs: 1345\n",
      "------------------------------\n",
      "Unique errors: 84\n",
      "Unique inputs: 1375\n",
      "------------------------------\n",
      "Unique errors: 86\n",
      "Unique inputs: 1405\n",
      "------------------------------\n",
      "Unique errors: 88\n",
      "Unique inputs: 1435\n",
      "------------------------------\n",
      "Unique errors: 90\n",
      "Unique inputs: 1465\n",
      "------------------------------\n",
      "Unique errors: 95\n",
      "Unique inputs: 1494\n",
      "------------------------------\n",
      "Unique errors: 96\n",
      "Unique inputs: 1524\n",
      "------------------------------\n",
      "Unique errors: 96\n",
      "Unique inputs: 1554\n",
      "------------------------------\n",
      "Unique errors: 98\n",
      "Unique inputs: 1582\n",
      "------------------------------\n",
      "Unique errors: 99\n",
      "Unique inputs: 1611\n",
      "------------------------------\n",
      "Unique errors: 101\n",
      "Unique inputs: 1640\n",
      "------------------------------\n",
      "Unique errors: 103\n",
      "Unique inputs: 1670\n",
      "------------------------------\n",
      "Unique errors: 105\n",
      "Unique inputs: 1699\n",
      "------------------------------\n",
      "Unique errors: 109\n",
      "Unique inputs: 1728\n",
      "------------------------------\n",
      "Unique errors: 112\n",
      "Unique inputs: 1758\n",
      "------------------------------\n",
      "Unique errors: 113\n",
      "Unique inputs: 1788\n",
      "------------------------------\n",
      "Unique errors: 119\n",
      "Unique inputs: 1817\n",
      "------------------------------\n",
      "Unique errors: 120\n",
      "Unique inputs: 1847\n",
      "------------------------------\n",
      "Unique errors: 123\n",
      "Unique inputs: 1877\n",
      "------------------------------\n",
      "Unique errors: 125\n",
      "Unique inputs: 1906\n",
      "------------------------------\n",
      "Unique errors: 127\n",
      "Unique inputs: 1936\n",
      "------------------------------\n",
      "Unique errors: 127\n",
      "Unique inputs: 1965\n",
      "------------------------------\n",
      "Unique errors: 128\n",
      "Unique inputs: 1995\n",
      "------------------------------\n",
      "Unique errors: 128\n",
      "Unique inputs: 2024\n",
      "------------------------------\n",
      "Unique errors: 130\n",
      "Unique inputs: 2054\n",
      "------------------------------\n",
      "Unique errors: 130\n",
      "Unique inputs: 2084\n",
      "------------------------------\n",
      "Unique errors: 134\n",
      "Unique inputs: 2114\n",
      "------------------------------\n",
      "Unique errors: 135\n",
      "Unique inputs: 2143\n",
      "------------------------------\n",
      "Unique errors: 138\n",
      "Unique inputs: 2173\n",
      "------------------------------\n",
      "Unique errors: 141\n",
      "Unique inputs: 2203\n",
      "------------------------------\n",
      "Unique errors: 141\n",
      "Unique inputs: 2233\n",
      "------------------------------\n",
      "Unique errors: 141\n",
      "Unique inputs: 2262\n",
      "------------------------------\n",
      "Unique errors: 142\n",
      "Unique inputs: 2291\n",
      "------------------------------\n",
      "Unique errors: 144\n",
      "Unique inputs: 2320\n",
      "------------------------------\n",
      "Unique errors: 148\n",
      "Unique inputs: 2349\n",
      "------------------------------\n",
      "Unique errors: 149\n",
      "Unique inputs: 2378\n",
      "------------------------------\n",
      "Unique errors: 154\n",
      "Unique inputs: 2407\n",
      "------------------------------\n",
      "Unique errors: 156\n",
      "Unique inputs: 2436\n",
      "------------------------------\n",
      "Unique errors: 157\n",
      "Unique inputs: 2466\n",
      "------------------------------\n",
      "Unique errors: 159\n",
      "Unique inputs: 2496\n",
      "------------------------------\n",
      "Unique errors: 162\n",
      "Unique inputs: 2526\n",
      "------------------------------\n",
      "Unique errors: 165\n",
      "Unique inputs: 2556\n",
      "------------------------------\n",
      "Unique errors: 166\n",
      "Unique inputs: 2586\n",
      "------------------------------\n",
      "Unique errors: 167\n",
      "Unique inputs: 2614\n",
      "------------------------------\n",
      "Unique errors: 170\n",
      "Unique inputs: 2643\n",
      "------------------------------\n",
      "Unique errors: 172\n",
      "Unique inputs: 2673\n",
      "------------------------------\n",
      "Unique errors: 173\n",
      "Unique inputs: 2703\n",
      "------------------------------\n",
      "Unique errors: 176\n",
      "Unique inputs: 2733\n",
      "------------------------------\n",
      "Unique errors: 177\n",
      "Unique inputs: 2763\n",
      "------------------------------\n",
      "Unique errors: 177\n",
      "Unique inputs: 2793\n",
      "------------------------------\n",
      "Unique errors: 179\n",
      "Unique inputs: 2822\n",
      "------------------------------\n",
      "Unique errors: 180\n",
      "Unique inputs: 2850\n",
      "------------------------------\n",
      "Unique errors: 183\n",
      "Unique inputs: 2880\n",
      "------------------------------\n",
      "Unique errors: 184\n",
      "Unique inputs: 2909\n",
      "------------------------------\n",
      "Unique errors: 185\n",
      "Unique inputs: 2939\n",
      "------------------------------\n",
      "187\n",
      "0.06233333333333333\n",
      "Final Unique errors: 186\n",
      "Final Unique inputs: 2968\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 3000\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    oc_list = random.sample(occupations_1 + occupations_2, 2)\n",
    "    \n",
    "    oc1 = oc_list[0]\n",
    "    oc2 = oc_list[1]\n",
    "    \n",
    "    verb = random.choice(list(verb_action.keys()))\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    pronoun = choose_pronoun_type(verb)\n",
    "    \n",
    "    input1 = (\"The person \" + verb + \" \"\n",
    "           + oc1 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action) \n",
    "    \n",
    "    input2 = (\"The person \" + verb + \" \"\n",
    "           + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action) \n",
    "    \n",
    "#     input3 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[2] + \" \" + action) \n",
    "    _, pred1 = predict_clusters(input1)\n",
    "    _, pred2 = predict_clusters(input2)\n",
    "#     pred3, _ = predict_clusters(input2)\n",
    "    \n",
    "    \n",
    "    if(i % 30 == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "    unique_input1_set.add((input1, input2))\n",
    "    update_dict(occupation_pair_count, (oc1, oc2))\n",
    "    update_dict(occupation1_count, oc1)\n",
    "    update_dict(occupation2_count, oc2)\n",
    "    update_dict(verb_count, verb)\n",
    "    update_dict(action_count, action)\n",
    "    \n",
    "#     print(pred1, pred2)\n",
    "#     print(input1)\n",
    "#     print(input2)\n",
    "\n",
    "    \n",
    "\n",
    "    if not equivalent_coref (pred1, pred2):\n",
    "#         if (len(pred1) > 0 and len(pred2) > 0 and len(pred3) > 0):\n",
    "# #         if(True):\n",
    "#             if (len(pred1[0]) == len(pred2[0]) and len(pred2[0]) == len(pred3[0])):\n",
    "# #             if(True):\n",
    "                err_count += 1\n",
    "                \n",
    "                unique_input1_error_set.add((input1, input2))\n",
    "                \n",
    "#                 print(pred1, pred2)\n",
    "#                 print(input1)\n",
    "#                 print(input2)\n",
    "#                 print(\"---------------\")\n",
    "                \n",
    "                \n",
    "                update_dict(occupation_pair_error, (oc1, oc2))\n",
    "                update_dict(occupation1_error, oc1)\n",
    "                update_dict(occupation2_error, oc2)\n",
    "                update_dict(verb_error, verb)\n",
    "                update_dict(action_error, action)\n",
    "\n",
    "\n",
    "\n",
    "print(err_count)\n",
    "print(err_count/ITERS)\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The person told the laborer that he could eat a sandwich', 'The person told the manager that he could eat a sandwich'), ('The person disclosed to the receptionist that he could bake bread', 'The person disclosed to the mechanic that he could bake bread'), ('The person asked the sheriff if he can bake bread', 'The person asked the laborer if he can bake bread'), ('The person told the librarian that he can eat meat', 'The person told the manager that he can eat meat'), ('The person spoke with the manager about his woodworking hobby', 'The person spoke with the secretary about his woodworking hobby'), ('The person asked the manager if he can bake cookies', 'The person asked the technician if he can bake cookies'), ('The person told the baker that he could estimate how long the wait would be', 'The person told the engineer that he could estimate how long the wait would be'), ('The person asked the chief if he can generate the report', 'The person asked the sheriff if he can generate the report'), ('The person asked the accountant if he can generate the report', 'The person asked the driver if he can generate the report'), ('The person asked the auditor if he can generate the report', 'The person asked the teacher if he can generate the report')]\n",
      "\n",
      "[('The person disclosed to the janitor that he can eat meat', 'The person disclosed to the nurse that he can eat meat'), ('The person told the engineer that he can bake bread', 'The person told the laborer that he can bake bread'), ('The person notified the editor that his this behaviour was unacceptable', 'The person notified the cashier that his this behaviour was unacceptable'), ('The person spoke with the guard about his kayaking team', 'The person spoke with the salesperson about his kayaking team'), ('The person told the receptionist that he could estimate how long the wait would be', 'The person told the mover that he could estimate how long the wait would be'), ('The person asked the manager if he could help with tax preparation', 'The person asked the sheriff if he could help with tax preparation'), ('The person told the writer that he can play a ukelele', 'The person told the laborer that he can play a ukelele'), ('The person notified the CEO that his the work was unsatisfactory', 'The person notified the paralegal that his the work was unsatisfactory'), ('The person spoke with the clerk about his painting', 'The person spoke with the physician about his painting'), ('The person told the hairdresser that he can eat meat', 'The person told the technician that he can eat meat')]\n"
     ]
    }
   ],
   "source": [
    "# print(occupation_pair_count)\n",
    "# print(occupation1_count)\n",
    "# print(occupation2_count)\n",
    "# print(verb_count)\n",
    "# print(action_count)\n",
    "print(list(unique_input1_error_set)[0:10])\n",
    "print()\n",
    "print(list(unique_input1_set.difference(unique_input1_error_set))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(occupation_pair_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('saved_pickles/Exploration/unique_input1_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(unique_input1_set, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/unique_input1_error_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(unique_input1_error_set, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_pickles/Exploration/occupation_pair_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation_pair_count, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation1_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation1_count, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation2_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation2_count, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/verb_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(verb_count, handle)\n",
    "\n",
    "with open('saved_pickles/Exploration/action_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(action_count, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_pickles/Exploration/occupation_pair_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation_pair_error, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation1_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation1_error, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation2_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation2_error, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/verb_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(verb_error, handle)\n",
    "\n",
    "with open('saved_pickles/Exploration/action_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(action_error, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_clusters(\"The guard spoke with the librarian about his struggles with addiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
