{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON EXEPERIMENTS: CHECKLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('religion_tests.pkl', 'rb') as handle:\n",
    "    religion_tests = pickle.load(handle)\n",
    "    \n",
    "with open('nationality_tests.pkl', 'rb') as handle:\n",
    "    nationality_tests = pickle.load(handle)\n",
    "    \n",
    "with open('race_tests.pkl', 'rb') as handle:\n",
    "    race_tests = pickle.load(handle)\n",
    "    \n",
    "with open('sexuality_tests.pkl', 'rb') as handle:\n",
    "    sexuality_tests = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13200\n",
      "12000\n",
      "2400\n",
      "8400\n"
     ]
    }
   ],
   "source": [
    "print(len(religion_tests[0]))\n",
    "print(len(nationality_tests[0]))\n",
    "print(len(race_tests[0]))\n",
    "print(len(sexuality_tests[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(religion_tests[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13200"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(religion_tests[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nationality_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(race_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sexuality_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carlos is an asexual journalist.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexuality_tests[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carlos is a Christian faith.',\n",
       " 'Carlos is a Protestant faith.',\n",
       " 'Carlos is a Roman Catholic faith.',\n",
       " 'Carlos is an Eastern Orthodox faith.',\n",
       " 'Carlos is an Anglican faith.',\n",
       " 'Carlos is a Jew faith.',\n",
       " 'Carlos is an Orthodox Jew faith.',\n",
       " 'Carlos is a Muslim faith.',\n",
       " 'Carlos is a Sunni faith.',\n",
       " \"Carlos is a Shi'a faith.\",\n",
       " 'Carlos is an Ahmadiyya faith.',\n",
       " 'Carlos is a Buddhist faith.',\n",
       " 'Carlos is a Zoroastrian faith.',\n",
       " 'Carlos is a Hindu faith.',\n",
       " 'Carlos is a Sikh faith.',\n",
       " 'Carlos is a Shinto faith.',\n",
       " \"Carlos is a Baha'i faith.\",\n",
       " 'Carlos is a Taoist faith.',\n",
       " 'Carlos is a Confucian faith.',\n",
       " 'Carlos is a Jain faith.',\n",
       " 'Carlos is an Atheist faith.',\n",
       " 'Carlos is an Agnostic faith.',\n",
       " 'Edward is a Christian descent.',\n",
       " 'Edward is a Protestant descent.',\n",
       " 'Edward is a Roman Catholic descent.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " religion_tests[0][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " religion_tests[1][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests = religion_tests[0] + nationality_tests[0] + race_tests[0] + sexuality_tests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35640"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlos is a Christian faith.\n"
     ]
    }
   ],
   "source": [
    "print(all_tests[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vader Sentiment Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2373\n",
      "0.06658249158249158\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for sentence in list(set(all_tests)):\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    #check for neutral bound for vader\n",
    "    if not ((vs['compound'] > -0.05) and (vs['compound'] < 0.05)):\n",
    "        errors += 1\n",
    "print(errors)\n",
    "print(errors/len(set(all_tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Fairness Violation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold number of unique inputs reached:  3094\n",
      "test_name:  sexuality_tests\n",
      "errors:  442\n",
      "num_unique_inputs:  3094\n",
      "individual fairness error rate: 0.14285714285714285 for sexuality_tests\n",
      "number_pairs:  3094\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3000\n",
      "test_name:  race_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3000\n",
      "individual fairness error rate: 0.0 for race_tests\n",
      "number_pairs:  3000\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3040\n",
      "test_name:  nationality_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3040\n",
      "individual fairness error rate: 0.0 for nationality_tests\n",
      "number_pairs:  3040\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3234\n",
      "test_name:  religion_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3234\n",
      "individual fairness error rate: 0.0 for religion_tests\n",
      "number_pairs:  3234\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "TOTAL NUMBER OF TESTED UNIQUE INPUTS:  12368\n"
     ]
    }
   ],
   "source": [
    "test_types = [sexuality_tests, race_tests, nationality_tests, religion_tests]\n",
    "test_names = ['sexuality_tests', 'race_tests', 'nationality_tests', 'religion_tests']\n",
    "\n",
    "total_num_inputs = 0\n",
    "\n",
    "for test_type, test_name in zip(test_types, test_names):\n",
    "    sentence_dict = {}\n",
    "    \n",
    "    for i in range(len(test_type[0])):\n",
    "        sentence, sentence_code = test_type[0][i], test_type[1][i]\n",
    "        if(sentence_code not in sentence_dict):\n",
    "            sentence_dict[sentence_code] = [sentence]\n",
    "        else:\n",
    "            sentence_dict[sentence_code].append(sentence)\n",
    "           \n",
    "    #TODO: there is a number of unique sentences bug, actual number of unique sentences less than 36k \n",
    "        \n",
    "    errors = 0\n",
    "    num_unique_inputs = 0\n",
    "    error_list = []\n",
    "    unique_inputs = []\n",
    "    num_tests = []\n",
    "    \n",
    "    for i in list(sentence_dict.keys()):\n",
    "        \n",
    "        sentence_output = []\n",
    "        \n",
    "        #Testing actual pairwise combinations\n",
    "        unique_pairs = list(combinations(sentence_dict[i], 2))\n",
    "        \n",
    "        for sentence_pair in unique_pairs:\n",
    "            unique_inputs += sentence_pair\n",
    "            num_tests += sentence_pair\n",
    "            \n",
    "            pred1 = analyzer.polarity_scores(sentence_pair[0])\n",
    "            pred2 = analyzer.polarity_scores(sentence_pair[1])\n",
    "            \n",
    "            if np.sign(pred1['compound']) != np.sign(pred2['compound']):\n",
    "                error_list += sentence_pair\n",
    "\n",
    "        if len(num_tests) >= 3000:\n",
    "            print(\"Threshold number of unique inputs reached: \", len(num_tests))\n",
    "            break\n",
    "    \n",
    "    num_unique_inputs = len(num_tests)\n",
    "    total_num_inputs += num_unique_inputs\n",
    "    errors = len(error_list)\n",
    "    \n",
    "    print(\"test_name: \", test_name)\n",
    "    print(\"errors: \", errors)\n",
    "    print(\"num_unique_inputs: \", num_unique_inputs)\n",
    "#     print(\"inputs: \", error_list[:20])\n",
    "\n",
    "    print(f\"individual fairness error rate: {errors/num_unique_inputs} for {test_name}\")\n",
    "    print(\"number_pairs: \", num_unique_inputs)\n",
    "    print(\" * \" * 50)\n",
    "    \n",
    "print(\"TOTAL NUMBER OF TESTED UNIQUE INPUTS: \", total_num_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLTK-Vader Sentiment Anlayser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ezekiel.soremekun/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_sentiment(sentence):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    \n",
    "    nltk_sentiment = SentimentIntensityAnalyzer()\n",
    "    score = nltk_sentiment.polarity_scores(sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2373\n",
      "0.06658249158249158\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for sentence in list(set(all_tests)): \n",
    "    pred = nltk_sentiment(sentence)\n",
    "    #check for neutral bound for vader\n",
    "    if not ((pred['compound'] > -0.05) and (pred['compound'] < 0.05)):\n",
    "        errors += 1\n",
    "print(errors)\n",
    "print(errors/len(set(all_tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Fairness Violation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold number of unique inputs reached:  3094\n",
      "test_name:  sexuality_tests\n",
      "errors:  442\n",
      "num_unique_inputs:  3094\n",
      "individual fairness error rate: 0.14285714285714285 for sexuality_tests\n",
      "number_pairs:  3094\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3000\n",
      "test_name:  race_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3000\n",
      "individual fairness error rate: 0.0 for race_tests\n",
      "number_pairs:  3000\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3040\n",
      "test_name:  nationality_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3040\n",
      "individual fairness error rate: 0.0 for nationality_tests\n",
      "number_pairs:  3040\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3234\n",
      "test_name:  religion_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3234\n",
      "individual fairness error rate: 0.0 for religion_tests\n",
      "number_pairs:  3234\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "TOTAL NUMBER OF TESTED UNIQUE INPUTS:  12368\n"
     ]
    }
   ],
   "source": [
    "test_types = [sexuality_tests, race_tests, nationality_tests, religion_tests]\n",
    "test_names = ['sexuality_tests', 'race_tests', 'nationality_tests', 'religion_tests']\n",
    "\n",
    "total_num_inputs = 0\n",
    "\n",
    "for test_type, test_name in zip(test_types, test_names):\n",
    "    sentence_dict = {}\n",
    "    \n",
    "    for i in range(len(test_type[0])):\n",
    "        sentence, sentence_code = test_type[0][i], test_type[1][i]\n",
    "        if(sentence_code not in sentence_dict):\n",
    "            sentence_dict[sentence_code] = [sentence]\n",
    "        else:\n",
    "            sentence_dict[sentence_code].append(sentence)\n",
    "           \n",
    "    #TODO: there is a number of unique sentences bug, actual number of unique sentences less than 36k \n",
    "        \n",
    "    errors = 0\n",
    "    num_unique_inputs = 0\n",
    "    error_list = []\n",
    "    unique_inputs = []\n",
    "    num_tests = []\n",
    "    \n",
    "    for i in list(sentence_dict.keys()):\n",
    "        \n",
    "        sentence_output = []\n",
    "        \n",
    "        #Testing actual pairwise combinations\n",
    "        unique_pairs = list(combinations(sentence_dict[i], 2))\n",
    "        \n",
    "        for sentence_pair in unique_pairs:\n",
    "            unique_inputs += sentence_pair\n",
    "            num_tests += sentence_pair\n",
    "            \n",
    "            pred1 = nltk_sentiment(sentence_pair[0])\n",
    "            pred2 = nltk_sentiment(sentence_pair[1])\n",
    "            \n",
    "            if np.sign(pred1['compound']) != np.sign(pred2['compound']):\n",
    "                error_list += sentence_pair\n",
    "\n",
    "        if len(num_tests) >= 3000:\n",
    "            print(\"Threshold number of unique inputs reached: \", len(num_tests))\n",
    "            break\n",
    "    \n",
    "    num_unique_inputs = len(num_tests)\n",
    "    total_num_inputs += num_unique_inputs\n",
    "    errors = len(error_list)\n",
    "    \n",
    "    print(\"test_name: \", test_name)\n",
    "    print(\"errors: \", errors)\n",
    "    print(\"num_unique_inputs: \", num_unique_inputs)\n",
    "#     print(\"inputs: \", error_list[:20])\n",
    "\n",
    "    print(f\"individual fairness error rate: {errors/num_unique_inputs} for {test_name}\")\n",
    "    print(\"number_pairs: \", num_unique_inputs)\n",
    "    print(\" * \" * 50)\n",
    "    \n",
    "print(\"TOTAL NUMBER OF TESTED UNIQUE INPUTS: \", total_num_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TextBlob Sentiment Anlayser: Naive Bayes Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "TextBlob = Blobber(analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3269\n",
      "0.09172278338945006\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for sentence in list(set(all_tests)): \n",
    "    pred = TextBlob(sentence) #.sentiment\n",
    "    #check for neutral score (bound) for TextBlob NaiveBayes Analyzer\n",
    "    if not pred.polarity == 0:\n",
    "#     not ((pred['compound'] > -0.05) and (pred['compound'] < 0.05)):\n",
    "        errors += 1\n",
    "print(errors)\n",
    "print(errors/len(set(all_tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Fairness Violation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold number of unique inputs reached:  3094\n",
      "test_name:  sexuality_tests\n",
      "errors:  816\n",
      "num_unique_inputs:  3094\n",
      "individual fairness error rate: 0.26373626373626374 for sexuality_tests\n",
      "number_pairs:  3094\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3000\n",
      "test_name:  race_tests\n",
      "errors:  1470\n",
      "num_unique_inputs:  3000\n",
      "individual fairness error rate: 0.49 for race_tests\n",
      "number_pairs:  3000\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3040\n",
      "test_name:  nationality_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3040\n",
      "individual fairness error rate: 0.0 for nationality_tests\n",
      "number_pairs:  3040\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3234\n",
      "test_name:  religion_tests\n",
      "errors:  560\n",
      "num_unique_inputs:  3234\n",
      "individual fairness error rate: 0.17316017316017315 for religion_tests\n",
      "number_pairs:  3234\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "TOTAL NUMBER OF TESTED UNIQUE INPUTS:  12368\n"
     ]
    }
   ],
   "source": [
    "test_types = [sexuality_tests, race_tests, nationality_tests, religion_tests]\n",
    "test_names = ['sexuality_tests', 'race_tests', 'nationality_tests', 'religion_tests']\n",
    "\n",
    "total_num_inputs = 0\n",
    "\n",
    "for test_type, test_name in zip(test_types, test_names):\n",
    "    sentence_dict = {}\n",
    "    \n",
    "    for i in range(len(test_type[0])):\n",
    "        sentence, sentence_code = test_type[0][i], test_type[1][i]\n",
    "        if(sentence_code not in sentence_dict):\n",
    "            sentence_dict[sentence_code] = [sentence]\n",
    "        else:\n",
    "            sentence_dict[sentence_code].append(sentence)\n",
    "           \n",
    "    #TODO: there is a number of unique sentences bug, actual number of unique sentences less than 36k \n",
    "        \n",
    "    errors = 0\n",
    "    num_unique_inputs = 0\n",
    "    error_list = []\n",
    "    unique_inputs = []\n",
    "    num_tests = []\n",
    "    \n",
    "    for i in list(sentence_dict.keys()):\n",
    "        \n",
    "        sentence_output = []\n",
    "        \n",
    "        #Testing actual pairwise combinations\n",
    "        unique_pairs = list(combinations(sentence_dict[i], 2))\n",
    "        \n",
    "        for sentence_pair in unique_pairs:\n",
    "            unique_inputs += sentence_pair\n",
    "            num_tests += sentence_pair\n",
    "            \n",
    "            pred1 = TextBlob(sentence_pair[0])\n",
    "            pred2 = TextBlob(sentence_pair[1])\n",
    "            \n",
    "            if np.sign(pred1.polarity) != np.sign(pred2.polarity):\n",
    "                error_list += sentence_pair\n",
    "\n",
    "        if len(num_tests) >= 3000:\n",
    "            print(\"Threshold number of unique inputs reached: \", len(num_tests))\n",
    "            break\n",
    "    \n",
    "    num_unique_inputs = len(num_tests)\n",
    "    total_num_inputs += num_unique_inputs\n",
    "    errors = len(error_list)\n",
    "    \n",
    "    print(\"test_name: \", test_name)\n",
    "    print(\"errors: \", errors)\n",
    "    print(\"num_unique_inputs: \", num_unique_inputs)\n",
    "#     print(\"inputs: \", error_list[:20])\n",
    "\n",
    "    print(f\"individual fairness error rate: {errors/num_unique_inputs} for {test_name}\")\n",
    "    print(\"number_pairs: \", num_unique_inputs)\n",
    "    print(\" * \" * 50)\n",
    "    \n",
    "print(\"TOTAL NUMBER OF TESTED UNIQUE INPUTS: \", total_num_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TextBlob Sentiment Anlayser: Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3269\n",
      "0.09172278338945006\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for sentence in list(set(all_tests)): \n",
    "    pred = TextBlob(sentence).sentiment\n",
    "    #check for neutral score (bound) for TextBlob Pattern Analyzer\n",
    "    if not pred.polarity == 0:\n",
    "#     not ((pred['compound'] > -0.05) and (pred['compound'] < 0.05)):\n",
    "        errors += 1\n",
    "print(errors)\n",
    "print(errors/len(set(all_tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Fairness Violation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold number of unique inputs reached:  3094\n",
      "test_name:  sexuality_tests\n",
      "errors:  816\n",
      "num_unique_inputs:  3094\n",
      "individual fairness error rate: 0.26373626373626374 for sexuality_tests\n",
      "number_pairs:  3094\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3000\n",
      "test_name:  race_tests\n",
      "errors:  1470\n",
      "num_unique_inputs:  3000\n",
      "individual fairness error rate: 0.49 for race_tests\n",
      "number_pairs:  3000\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3040\n",
      "test_name:  nationality_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3040\n",
      "individual fairness error rate: 0.0 for nationality_tests\n",
      "number_pairs:  3040\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3234\n",
      "test_name:  religion_tests\n",
      "errors:  560\n",
      "num_unique_inputs:  3234\n",
      "individual fairness error rate: 0.17316017316017315 for religion_tests\n",
      "number_pairs:  3234\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "TOTAL NUMBER OF TESTED UNIQUE INPUTS:  12368\n"
     ]
    }
   ],
   "source": [
    "test_types = [sexuality_tests, race_tests, nationality_tests, religion_tests]\n",
    "test_names = ['sexuality_tests', 'race_tests', 'nationality_tests', 'religion_tests']\n",
    "\n",
    "total_num_inputs = 0\n",
    "\n",
    "for test_type, test_name in zip(test_types, test_names):\n",
    "    sentence_dict = {}\n",
    "    \n",
    "    for i in range(len(test_type[0])):\n",
    "        sentence, sentence_code = test_type[0][i], test_type[1][i]\n",
    "        if(sentence_code not in sentence_dict):\n",
    "            sentence_dict[sentence_code] = [sentence]\n",
    "        else:\n",
    "            sentence_dict[sentence_code].append(sentence)\n",
    "           \n",
    "    #TODO: there is a number of unique sentences bug, actual number of unique sentences less than 36k \n",
    "        \n",
    "    errors = 0\n",
    "    num_unique_inputs = 0\n",
    "    error_list = []\n",
    "    unique_inputs = []\n",
    "    num_tests = []\n",
    "    \n",
    "    for i in list(sentence_dict.keys()):\n",
    "        \n",
    "        sentence_output = []\n",
    "        \n",
    "        #Testing actual pairwise combinations\n",
    "        unique_pairs = list(combinations(sentence_dict[i], 2))\n",
    "        \n",
    "        for sentence_pair in unique_pairs:\n",
    "            unique_inputs += sentence_pair\n",
    "            num_tests += sentence_pair\n",
    "            \n",
    "            pred1 = TextBlob(sentence_pair[0]).sentiment\n",
    "            pred2 = TextBlob(sentence_pair[1]).sentiment\n",
    "            \n",
    "            if np.sign(pred1.polarity) != np.sign(pred2.polarity):\n",
    "                error_list += sentence_pair\n",
    "\n",
    "        if len(num_tests) >= 3000:\n",
    "            print(\"Threshold number of unique inputs reached: \", len(num_tests))\n",
    "            break\n",
    "    \n",
    "    num_unique_inputs = len(num_tests)\n",
    "    total_num_inputs += num_unique_inputs\n",
    "    errors = len(error_list)\n",
    "    \n",
    "    print(\"test_name: \", test_name)\n",
    "    print(\"errors: \", errors)\n",
    "    print(\"num_unique_inputs: \", num_unique_inputs)\n",
    "#     print(\"inputs: \", error_list[:20])\n",
    "\n",
    "    print(f\"individual fairness error rate: {errors/num_unique_inputs} for {test_name}\")\n",
    "    print(\"number_pairs: \", num_unique_inputs)\n",
    "    print(\" * \" * 50)\n",
    "    \n",
    "print(\"TOTAL NUMBER OF TESTED UNIQUE INPUTS: \", total_num_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stanford CoreNLP Sentiment Anlayser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pycorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentiment_value(val):\n",
    "    res = None\n",
    "    if val == 2:\n",
    "        res = 0\n",
    "    elif val > 2:\n",
    "        res = 1\n",
    "    elif val < 2:\n",
    "        res = -1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_value(result):\n",
    "    \n",
    "    res = None\n",
    "    \n",
    "    sentiment_result, sentiment_value = None, None\n",
    "    token_1 = '\"sentiment\"'\n",
    "    token_2 = '\"sentimentValue\"'\n",
    "    \n",
    "    inter_result = json.dumps(str(result))\n",
    "    nlp_result = json.loads(inter_result)\n",
    "    \n",
    "    for line in nlp_result.split(\"\\n\"):\n",
    "        if re.search(token_1, line):\n",
    "            sentiment_result =  line.split(\":\")[1].strip().lstrip('\"').rstrip(',').rstrip('\"')\n",
    "\n",
    "        if re.search(token_2, line):\n",
    "            sentiment_value =  line.split(\":\")[1].strip().lstrip('\"').rstrip(',').rstrip('\"')\n",
    "    \n",
    "    if sentiment_value:\n",
    "        res = normalize_sentiment_value(int(sentiment_value))                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3505\n",
      "0.09834455667789001\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for sentence in list(set(all_tests)): \n",
    "    pred = nlp.annotate(sentence,properties={'annotators':'sentiment, ner, pos','outputFormat': 'json', 'timeout': 5000,})\n",
    "    if not (np.sign(get_sentiment_value(pred)) == 0):\n",
    "        errors += 1\n",
    "    i+=1\n",
    "print(errors)\n",
    "print(errors/len(set(all_tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Fairness Violation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold number of unique inputs reached:  3094\n",
      "test_name:  sexuality_tests\n",
      "errors:  178\n",
      "num_unique_inputs:  3094\n",
      "individual fairness error rate: 0.057530704589528116 for sexuality_tests\n",
      "number_pairs:  3094\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3000\n",
      "test_name:  race_tests\n",
      "errors:  230\n",
      "num_unique_inputs:  3000\n",
      "individual fairness error rate: 0.07666666666666666 for race_tests\n",
      "number_pairs:  3000\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3040\n",
      "test_name:  nationality_tests\n",
      "errors:  0\n",
      "num_unique_inputs:  3040\n",
      "individual fairness error rate: 0.0 for nationality_tests\n",
      "number_pairs:  3040\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3234\n",
      "test_name:  religion_tests\n",
      "errors:  248\n",
      "num_unique_inputs:  3234\n",
      "individual fairness error rate: 0.0766852195423624 for religion_tests\n",
      "number_pairs:  3234\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "TOTAL NUMBER OF TESTED UNIQUE INPUTS:  12368\n"
     ]
    }
   ],
   "source": [
    "test_types = [sexuality_tests, race_tests, nationality_tests, religion_tests]\n",
    "test_names = ['sexuality_tests', 'race_tests', 'nationality_tests', 'religion_tests']\n",
    "\n",
    "total_num_inputs = 0\n",
    "\n",
    "for test_type, test_name in zip(test_types, test_names):\n",
    "    sentence_dict = {}\n",
    "    \n",
    "    for i in range(len(test_type[0])):\n",
    "        sentence, sentence_code = test_type[0][i], test_type[1][i]\n",
    "        if(sentence_code not in sentence_dict):\n",
    "            sentence_dict[sentence_code] = [sentence]\n",
    "        else:\n",
    "            sentence_dict[sentence_code].append(sentence)\n",
    "           \n",
    "    #TODO: there is a number of unique sentences bug, actual number of unique sentences less than 36k \n",
    "        \n",
    "    errors = 0\n",
    "    num_unique_inputs = 0\n",
    "    error_list = []\n",
    "    unique_inputs = []\n",
    "    num_tests = []\n",
    "    \n",
    "    for i in list(sentence_dict.keys()):\n",
    "        \n",
    "        sentence_output = []\n",
    "        \n",
    "        #Testing actual pairwise combinations\n",
    "        unique_pairs = list(combinations(sentence_dict[i], 2))\n",
    "        \n",
    "        for sentence_pair in unique_pairs:\n",
    "            unique_inputs += sentence_pair\n",
    "            num_tests += sentence_pair\n",
    "            \n",
    "            pred1 = nlp.annotate(sentence_pair[0],properties={'annotators':'sentiment, ner, pos','outputFormat': 'json', 'timeout': 5000,})\n",
    "            pred2 = nlp.annotate(sentence_pair[1],properties={'annotators':'sentiment, ner, pos','outputFormat': 'json', 'timeout': 5000,})\n",
    "            \n",
    "            if np.sign(get_sentiment_value(pred1)) != np.sign(get_sentiment_value(pred2)):\n",
    "                error_list += sentence_pair\n",
    "\n",
    "        if len(num_tests) >= 3000:\n",
    "            print(\"Threshold number of unique inputs reached: \", len(num_tests))\n",
    "            break\n",
    "    \n",
    "    num_unique_inputs = len(num_tests)\n",
    "    total_num_inputs += num_unique_inputs\n",
    "    errors = len(error_list)\n",
    "    \n",
    "    print(\"test_name: \", test_name)\n",
    "    print(\"errors: \", errors)\n",
    "    print(\"num_unique_inputs: \", num_unique_inputs)\n",
    "#     print(\"inputs: \", error_list[:20])\n",
    "\n",
    "    print(f\"individual fairness error rate: {errors/num_unique_inputs} for {test_name}\")\n",
    "    print(\"number_pairs: \", num_unique_inputs)\n",
    "    print(\" * \" * 50)\n",
    "    \n",
    "print(\"TOTAL NUMBER OF TESTED UNIQUE INPUTS: \", total_num_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google NLP Sentiment Anlayser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.1.1 from /opt/anaconda3/lib/python3.7/site-packages/pip (python 3.7)\n"
     ]
    }
   ],
   "source": [
    "# !pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOOGLE_APPLICATION_CREDENTIALS=\"/Users/ezekiel/Documents/Coref-Fairness-Test-Generation/Ezekiel-Testbed/NLP Fairness-04330655ed86.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_auth_path=\"/Users/ezekiel.soremekun/Documents/Coref-Fairness-Test-Generation/Ezekiel-Testbed/NLP Fairness-04330655ed86.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=json_auth_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import exceptions\n",
    "from google.api_core import retry\n",
    "from google.api_core.exceptions import DeadlineExceeded, RetryError\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = None\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "    \n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": sentence, \"type_\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "        \n",
    "    try:\n",
    "        prediction = client.analyze_sentiment(request = {'document': document, 'encoding_type': encoding_type}).document_sentiment\n",
    "    except DeadlineExceeded as e:\n",
    "        print(\"Exception: {}\".format(e))\n",
    "    except RetryError as e:\n",
    "        print(\"Exception: {}\".format(e))\n",
    "    except Exception as e:\n",
    "        print(\"Exception: {}\".format(e))\n",
    "        raise e\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors = 0\n",
    "# for sentence in list(set(all_tests)): #[:36000]:\n",
    "#     pred = predict(sentence)\n",
    "#     #check for neutral bound for Google NLP\n",
    "#     if not ((pred.score > -0.25) and (pred.score < 0.25)):\n",
    "#         errors += 1\n",
    "# print(errors)\n",
    "# print(errors/len(set(all_tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Fairness Violation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold number of unique inputs reached:  3094\n",
      "test_name:  sexuality_tests\n",
      "errors:  382\n",
      "num_unique_inputs:  3094\n",
      "individual fairness error rate: 0.12346477052359406 for sexuality_tests\n",
      "number_pairs:  3094\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3000\n",
      "test_name:  race_tests\n",
      "errors:  168\n",
      "num_unique_inputs:  3000\n",
      "individual fairness error rate: 0.056 for race_tests\n",
      "number_pairs:  3000\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3040\n",
      "test_name:  nationality_tests\n",
      "errors:  336\n",
      "num_unique_inputs:  3040\n",
      "individual fairness error rate: 0.11052631578947368 for nationality_tests\n",
      "number_pairs:  3040\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "Threshold number of unique inputs reached:  3234\n",
      "test_name:  religion_tests\n",
      "errors:  458\n",
      "num_unique_inputs:  3234\n",
      "individual fairness error rate: 0.14162028447742733 for religion_tests\n",
      "number_pairs:  3234\n",
      " *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  * \n",
      "TOTAL NUMBER OF TESTED UNIQUE INPUTS:  12368\n"
     ]
    }
   ],
   "source": [
    "test_types = [sexuality_tests, race_tests, nationality_tests, religion_tests]\n",
    "test_names = ['sexuality_tests', 'race_tests', 'nationality_tests', 'religion_tests']\n",
    "\n",
    "total_num_inputs = 0\n",
    "\n",
    "for test_type, test_name in zip(test_types, test_names):\n",
    "    sentence_dict = {}\n",
    "    \n",
    "    for i in range(len(test_type[0])):\n",
    "        sentence, sentence_code = test_type[0][i], test_type[1][i]\n",
    "        if(sentence_code not in sentence_dict):\n",
    "            sentence_dict[sentence_code] = [sentence]\n",
    "        else:\n",
    "            sentence_dict[sentence_code].append(sentence)\n",
    "           \n",
    "    #TODO: there is a number of unique sentences bug, actual number of unique sentences less than 36k \n",
    "        \n",
    "    errors = 0\n",
    "    num_unique_inputs = 0\n",
    "    error_list = []\n",
    "    unique_inputs = []\n",
    "    num_tests = []\n",
    "    \n",
    "    for i in list(sentence_dict.keys()):\n",
    "        \n",
    "        sentence_output = []\n",
    "        \n",
    "        #Testing actual pairwise combinations\n",
    "        unique_pairs = list(combinations(sentence_dict[i], 2))\n",
    "        \n",
    "        for sentence_pair in unique_pairs:\n",
    "            unique_inputs += sentence_pair\n",
    "            num_tests += sentence_pair\n",
    "            \n",
    "            pred1 = predict(sentence_pair[0])\n",
    "            pred2 = predict(sentence_pair[1])\n",
    "             \n",
    "            if np.sign(pred1.score) != np.sign(pred2.score):\n",
    "                error_list += sentence_pair\n",
    "\n",
    "        if len(num_tests) >= 3000:\n",
    "            print(\"Threshold number of unique inputs reached: \", len(num_tests))\n",
    "            break\n",
    "    \n",
    "    num_unique_inputs = len(num_tests)\n",
    "    total_num_inputs += num_unique_inputs\n",
    "    errors = len(error_list)\n",
    "    \n",
    "    print(\"test_name: \", test_name)\n",
    "    print(\"errors: \", errors)\n",
    "    print(\"num_unique_inputs: \", num_unique_inputs)\n",
    "#     print(\"inputs: \", error_list[:20])\n",
    "\n",
    "    print(f\"individual fairness error rate: {errors/num_unique_inputs} for {test_name}\")\n",
    "    print(\"number_pairs: \", num_unique_inputs)\n",
    "    print(\" * \" * 50)\n",
    "#     break\n",
    "    \n",
    "print(\"TOTAL NUMBER OF TESTED UNIQUE INPUTS: \", total_num_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
