{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Vader Sentiment Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema (based on EEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list_p1 = ['feels', 'feel', 'made me feel', 'was'] \n",
    "verb_list_p2 = ['saw', 'found himself/herself in a', 'told us all about the recent', 'talked to', 'goes to'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list = ['is' , 'was', 'talked to', 'goes to', 'feels', \\\n",
    "             'feel', 'made me feel', 'found himself/herself in', \\\n",
    "             'told us all about the recent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_female = ['this woman','this girl','my sister','my daughter', 'my wife',\\\n",
    "                 'my girlfriend', 'my mother', 'my aunt', 'my mom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_male = ['this man', 'this boy', 'my brother', 'my son', 'my husband', \\\n",
    "               'my boyfriend', 'my father', 'my uncle', 'my dad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_pronoun_female = [\"He\"]\n",
    "subj_pronoun_male = [\"She\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_pronoun_female = [\"her\"]\n",
    "obj_pronoun_male = [\"him\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_male_biased = ['the supervisor','the janitor','the cook','the mover','the laborer','the construction worker','the chief','the developer','the carpenter','the manager','the lawyer','the farmer','the driver','the salesperson','the physician','the guard','the analyst','the mechanic','the sheriff','the CEO','the technician','the accountant','the engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_female_biased = ['the cashier','the teacher','the nurse','the assistant','the secretary','the auditor','the cleaner','the receptionist','the clerk','the counselor','the designer','the hairdresser','the attendant','the writer','the housekeeper','the baker','the accountant','the editor','the librarian','the tailor','the teacher','the the librarian','the the nurse','the the paralegal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 30 male and female names\n",
    "#Data from (13/07/2020) https://www.ssa.gov/OACT/babynames/decades/century.html\n",
    "female_biased_names = ['Mary', 'Patricia', 'Jennifer', 'Linda', 'Elizabeth', 'Barbara', 'Susan', 'Jessica', \\\n",
    "                        'Sarah', 'Karen', 'Nancy', 'Margaret', 'Lisa', 'Betty', 'Dorothy ', 'Sandra', 'Ashley', \\\n",
    "                       'Kimberly', 'Donna', 'Emily', 'Michelle', 'Carol', 'Amanda', 'Melissa' , 'Deborah', \\\n",
    "                       'Stephanie', 'Rebecca', 'Laura', 'Sharon', 'Cynthia']\n",
    "male_biased_names = ['James', 'John ', 'Robert ', 'Michael ', 'William ', 'David ', 'Richard', 'Joseph', 'Thomas', \\\n",
    "                     'Charles', 'Christopher', 'Daniel', 'Matthew', 'Anthony', 'Donald', 'Mark', 'Paul', 'Steven', \\\n",
    "                     'Andrew', 'Kenneth', 'Joshua', 'George', 'Kevin', 'Brian', 'Edward', 'Ronald', 'Timothy', \\\n",
    "                     'Jason', 'Jeffrey', 'Ryan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from EEC\n",
    "African_American_Female_Names = ['Ebony', 'Jasmine', 'Lakisha', 'Latisha', 'Latoya', 'Nichelle', 'Shaniqua', 'Shereen', 'Tanisha', 'Tia']\n",
    "African_American_Male_Names = ['Alonzo', 'Alphonse', 'Darnell', 'Jamel', 'Jerome', 'Lamar', 'Leroy', 'Malik', 'Terrence', 'Torrance']\n",
    "European_American_Female_Names = ['Amanda', 'Betsy', 'Courtney', 'Ellen', 'Heather', 'Katie', 'Kristin', 'Melanie', 'Nancy', 'Stephanie']\n",
    "European_American_Male_Names = ['Adam', 'Alan', 'Andrew', 'Frank', 'Harry', 'Jack', 'Josh', 'Justin', 'Roger', 'Ryan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_male_names = European_American_Male_Names + African_American_Male_Names\n",
    "gen_female_names = European_American_Female_Names + African_American_Female_Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_american_names = African_American_Female_Names + African_American_Male_Names\n",
    "european_american_names = European_American_Female_Names + European_American_Male_Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_person_male_all = subj_pronoun_male + person_male # + occupations_male_biased\n",
    "subj_person_female_all = subj_pronoun_female + person_female # + occupations_female_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_person_male = obj_pronoun_male + person_male\n",
    "obj_person_female = obj_pronoun_female + person_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_states = [\"angry\", \"anxious\", \"ecstatic\", \"depressed\", \"annoyed\", \"discouraged\",\\\n",
    "                   \"excited\", \"devastated\", \"enraged\", \"fearful\", \"glad\", \"disappointed\",\\\n",
    "                   \"furious\", \"scared\", \"happy\", \"miserable\", \"irritated\", \"terrified\",\\\n",
    "                   \"relieved\", \"sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emotional_states = [\"ecstatic\", \"excited\", \"glad\", \"happy\", \"relieved\"]\n",
    "\n",
    "negative_emotional_states = [\"angry\", \"anxious\",\"depressed\", \"annoyed\", \"discouraged\",\\\n",
    "                             \"devastated\", \"enraged\", \"fearful\", \"disappointed\",\\\n",
    "                             \"furious\", \"scared\", \"miserable\", \"irritated\", \"terrified\", \"sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_situations = [\"annoying\", \"dreadful\", \"amazing\", \"depressing\", \\\n",
    "                       \"displeasing\", \"horrible\", \"funny\", \"gloomy\", \\\n",
    "                       \"irritating\", \"shocking\", \"great\", \"grim\", \\\n",
    "                       \"outrageous\", \"terrifying\", \"hilarious\", \"heartbreaking\", \\\n",
    "                       \"vexing\", \"threatening\", \"wonderful\", \"serious\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emotional_situations = [\"amazing\", \"funny\", \"great\", \"hilarious\",\"wonderful\"]\n",
    "\n",
    "negative_emotional_situations = [\"annoying\", \"dreadful\", \"depressing\", \"displeasing\", \"horrible\",\\\n",
    "                                \"gloomy\", \"irritating\", \"shocking\", \"grim\", \"outrageous\", \"terrifying\", \"heartbreaking\",\\\n",
    "                                \"vexing\",  \"threatening\", \"serious\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_subjs = [\"I made\", \"The situation makes\", \"The conversation with\"]\n",
    "verb_feel_list = [\"feel\", \"made me feel\", \"found himself/herself in a/an\", \"told us all about the recent\", \"was\", \\\n",
    "                  \"found herself in a/an\", \"found himself in a/an\"]\n",
    "end_noun = ['situation', 'events']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Exploration Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice =  random.choice([0, 1, 2])\n",
    "\n",
    "dice = 0\n",
    "\n",
    "#Noun choice\n",
    "if dice == 0:\n",
    "#     person_choice = random.choice(range(0, len(subj_person_male_all) - 1))\n",
    "#     subj_person_male = subj_person_male_all[person_choice]\n",
    "#     subj_person_female = subj_person_female_all[person_choice]\n",
    "    person_choice = random.choice(range(0, len(subj_person_male_all) - 1))\n",
    "    subj_person_male = person_male[person_choice]\n",
    "    subj_person_female = person_female[person_choice]    \n",
    "elif dice == 1:\n",
    "    subj_person_male = random.choice(subj_person_male_all)\n",
    "    subj_person_female = random.choice(subj_person_female_all)\n",
    "else:\n",
    "    subj_person_male = random.choice(occupations_male_biased)\n",
    "    subj_person_female = random.choice(occupations_female_biased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_state = random.choice(emotional_states)\n",
    "emotional_situation = random.choice(emotional_situations)\n",
    "\n",
    "verb1 = random.choice(verb_list_p1)\n",
    "verb_feel = random.choice(verb_feel_list)\n",
    "\n",
    "neutral_subj_1 = random.choice(neutral_subjs[:2])\n",
    "neutral_subj_2 = neutral_subjs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I made', 'The situation makes']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_subjs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct_1_female = \" \".join([subj_person_female,verb1,emotional_state + \".\"])\n",
    "# struct_1_male = \" \".join([subj_person_male, verb1, emotional_state + \".\"])\n",
    "\n",
    "# struct_2_female =  \" \".join([neutral_subj_1, subj_person_female, verb_feel_list[0], emotional_state + \".\" ])\n",
    "# struct_2_male =  \" \".join([neutral_subj_1, subj_person_male, verb_feel_list[0], emotional_state + \".\" ])\n",
    "\n",
    "# struct_3_female =  \" \".join([subj_person_female, verb_feel_list[1], emotional_state + \".\" ])\n",
    "# struct_3_male =  \" \".join([subj_person_male, verb_feel_list[1], emotional_state + \".\" ])\n",
    "\n",
    "# struct_3_female =  \" \".join([subj_person_female, verb_feel_list[1], emotional_state + \".\" ])\n",
    "# struct_3_male =  \" \".join([subj_person_male, verb_feel_list[1], emotional_state + \".\" ])\n",
    "\n",
    "# struct_4_female =  \" \".join([subj_person_female, verb_feel_list[5], emotional_situation, end_noun[0] + \".\"])\n",
    "# struct_4_male =  \" \".join([subj_person_male, verb_feel_list[6], emotional_situation, end_noun[0] + \".\"])\n",
    "\n",
    "# struct_5_female =  \" \".join([subj_person_female, verb_feel_list[3], emotional_situation, end_noun[1] + \".\"])\n",
    "# struct_5_male =  \" \".join([subj_person_male, verb_feel_list[3], emotional_situation, end_noun[1] + \".\"])\n",
    "\n",
    "# struct_6_female =  \" \".join([neutral_subj_2, subj_person_female, verb_feel_list[4], emotional_situation + \".\"])\n",
    "# struct_6_male =  \" \".join([neutral_subj_2, subj_person_male, verb_feel_list[4], emotional_situation + \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "struct_8_female =  \" \".join([neutral_subj_1, obj_pronoun_female[0], verb_feel_list[0], emotional_state + \".\" ])\n",
    "struct_8_male =  \" \".join([neutral_subj_1, obj_pronoun_male[0], verb_feel_list[0], emotional_state + \".\" ])\n",
    "\n",
    "struct_7_female =  \" \".join([neutral_subj_2, obj_pronoun_female[0], verb_feel_list[4], emotional_situation + \".\"])\n",
    "struct_7_male =  \" \".join([neutral_subj_2, obj_pronoun_male[0], verb_feel_list[4], emotional_situation + \".\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "I made her feel anxious.\n",
      "I made him feel anxious.\n",
      "------------------------------\n",
      "The conversation with her was vexing.\n",
      "The conversation with him was vexing.\n"
     ]
    }
   ],
   "source": [
    "# print(struct_4_female)\n",
    "# print(struct_4_male)\n",
    "print(\"-\" * 30)\n",
    "print(struct_8_female)\n",
    "print(struct_8_male)\n",
    "print(\"-\" * 30)\n",
    "print(struct_7_female)\n",
    "print(struct_7_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(struct_1_female)\n",
    "# print(struct_1_male)\n",
    "# print(\"-\" * 30)\n",
    "# print(struct_2_female)\n",
    "# print(struct_2_male)\n",
    "# print(\"-\" * 30)\n",
    "# print(struct_3_female)\n",
    "# print(struct_3_male)\n",
    "# print(\"-\" * 30)\n",
    "# print(struct_4_female)\n",
    "# print(struct_4_male)\n",
    "# print(\"-\" * 30)\n",
    "# print(struct_5_female)\n",
    "# print(struct_5_male)\n",
    "# print(\"-\" * 30)\n",
    "# print(struct_6_female)\n",
    "# print(struct_6_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions, Constants and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ezekiel/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_sentiment(sentence):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    \n",
    "    nltk_sentiment = SentimentIntensityAnalyzer()\n",
    "    score = nltk_sentiment.polarity_scores(sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_schema_oracle(inp):\n",
    "    res = 0\n",
    "    token_list = inp.rstrip(\".\").split()\n",
    "    for token in token_list:\n",
    "        if (token in positive_emotional_situations) or \\\n",
    "            (token in positive_emotional_states):\n",
    "            res = 1\n",
    "            break\n",
    "        elif (token in negative_emotional_situations) or \\\n",
    "            (token in negative_emotional_states):\n",
    "            res = -1\n",
    "            break           \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_prediction(input1, input2, unique_input1_error_set, err_count):\n",
    "    pred1 = nltk_sentiment(input1)\n",
    "    pred2 = nltk_sentiment(input2)\n",
    "    \n",
    "    verdict1 = run_schema_oracle(input1)\n",
    "    verdict2 = run_schema_oracle(input2)\n",
    "    assert(verdict1 == verdict2), \"ERROR: bug in run_schema_oracle() for inputs {}, {}\".format(input1, input2)\n",
    "    \n",
    "    if not ((np.sign(pred1['compound']) == np.sign(verdict1)) and (np.sign(pred2['compound'])  == np.sign(verdict2))): \n",
    "        err_count += 1\n",
    "        unique_input1_error_set.add(input1 + \"; \" + input2)          \n",
    "#             unique_input2_error_set.add(input2)\n",
    "#         print(\"verdicts: \", verdict1, verdict2)\n",
    "#         print(\"prediction: \", pred1, pred2)\n",
    "#         print(\"inp1: \", input1)\n",
    "#         print(\"inp2: \",input2)\n",
    "    return unique_input1_error_set, err_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 30 male and female names\n",
    "#List Data from EEC and (13/07/2020) https://www.ssa.gov/OACT/babynames/decades/century.html\n",
    "female_biased_names = gen_female_names + ['Mary', 'Patricia', 'Jennifer', 'Linda', 'Elizabeth', 'Barbara', 'Susan', 'Jessica', 'Sarah', 'Karen', 'Nancy', 'Margaret', 'Lisa', 'Betty', 'Dorothy ', 'Sandra', 'Ashley', 'Kimberly', 'Donna', 'Emily', 'Michelle', 'Carol', 'Amanda', 'Melissa' , 'Deborah', 'Stephanie', 'Rebecca', 'Laura', 'Sharon', 'Cynthia']\n",
    "male_biased_names = gen_male_names + ['James', 'John ', 'Robert ', 'Michael ', 'William ', 'David ', 'Richard', 'Joseph', 'Thomas', 'Charles', 'Christopher', 'Daniel', 'Matthew', 'Anthony', 'Donald', 'Mark', 'Paul', 'Steven', 'Andrew', 'Kenneth', 'Joshua', 'George', 'Kevin', 'Brian', 'Edward', 'Ronald', 'Timothy', 'Jason', 'Jeffrey', 'Ryan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subj_choice(choice):\n",
    "    if choice == 0:\n",
    "        person_choice = random.choice(range(0, len(subj_person_male_all) - 1))\n",
    "        subj_person_male = subj_person_male_all[person_choice]\n",
    "        subj_person_female = subj_person_female_all[person_choice]\n",
    "    elif choice == 1:\n",
    "        person_choice = random.choice(range(0, len(subj_person_male_all) - 1))\n",
    "        subj_person_male = random.choice(subj_person_male_all)\n",
    "        subj_person_female = random.choice(subj_person_female_all)\n",
    "    elif choice == 2:\n",
    "        subj_person_male = random.choice(occupations_male_biased)\n",
    "        subj_person_female = random.choice(occupations_female_biased)\n",
    "    elif choice == 3:\n",
    "        subj_person_male = random.choice(male_biased_names)\n",
    "        subj_person_female = random.choice(female_biased_names)\n",
    "    elif choice == 4:\n",
    "        subj_person_male = random.choice(gen_male_names)\n",
    "        subj_person_female = random.choice(gen_female_names)\n",
    "    elif choice == 5:\n",
    "        subj_person_male = random.choice(european_american_names)\n",
    "        subj_person_female = random.choice(european_american_names)\n",
    "    \n",
    "    return subj_person_male, subj_person_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tokens(choice):\n",
    "    resList = []\n",
    "    \n",
    "    subj_person_male, subj_person_female = subj_choice(choice)\n",
    "    \n",
    "    resList.append(subj_person_male)\n",
    "    resList.append(subj_person_female)\n",
    "\n",
    "    emotional_state = random.choice(emotional_states)\n",
    "    emotional_situation = random.choice(emotional_situations)\n",
    "    \n",
    "    resList.append(emotional_state)\n",
    "    resList.append(emotional_situation)\n",
    "\n",
    "    verb1 = random.choice(verb_list_p1)\n",
    "    verb_feel = random.choice(verb_feel_list)\n",
    "    \n",
    "    resList.append(verb1)\n",
    "    resList.append(verb_feel)\n",
    "\n",
    "    neutral_subj_1 = random.choice(neutral_subjs[:2])\n",
    "    neutral_subj_2 = neutral_subjs[2]\n",
    "    \n",
    "    resList.append(neutral_subj_1)\n",
    "    resList.append(neutral_subj_2)\n",
    "    \n",
    "    return resList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gender_specific_subject_sentence(list_tokens, verb_feel_list, schema_no):\n",
    "    \n",
    "    subj_person_male, subj_person_female, emotional_state, emotional_situation, verb1, verb_feel, \\\n",
    "        neutral_subj_1, neutral_subj_2 = list_tokens\n",
    "    \n",
    "    res_str_1, res_str_2 = \"\", \"\"\n",
    "\n",
    "    if schema_no == 0:\n",
    "        res_str_1 =   \" \".join([subj_person_female, verb1, emotional_state + \".\"])\n",
    "        res_str_2 =  \" \".join([subj_person_male, verb1, emotional_state + \".\"])\n",
    "    \n",
    "    elif schema_no == 1:\n",
    "        res_str_1 =  \" \".join([subj_person_female, verb_feel_list[1], emotional_state + \".\" ])\n",
    "        res_str_2 =  \" \".join([subj_person_male, verb_feel_list[1], emotional_state + \".\" ])      \n",
    "\n",
    "    elif schema_no == 2:\n",
    "        res_str_1 = \" \".join([subj_person_female, verb_feel_list[1], emotional_state + \".\" ]) \n",
    "        res_str_2 = \" \".join([subj_person_male, verb_feel_list[1], emotional_state + \".\" ])       \n",
    "\n",
    "    elif schema_no == 3:\n",
    "        res_str_1 = \" \".join([subj_person_female, verb_feel_list[5], emotional_situation, end_noun[0] + \".\"])\n",
    "        res_str_2 = \" \".join([subj_person_male, verb_feel_list[6], emotional_situation, end_noun[0] + \".\"])   \n",
    "    \n",
    "    elif schema_no == 4:\n",
    "        res_str_1 =  \" \".join([subj_person_female, verb_feel_list[3], emotional_situation, end_noun[1] + \".\"])\n",
    "        res_str_2 =  \" \".join([subj_person_male, verb_feel_list[3], emotional_situation, end_noun[1] + \".\"])         \n",
    "\n",
    "    return res_str_1, res_str_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neutral_subject_sentence(list_tokens, verb_feel_list, schema_no):\n",
    "    \n",
    "    subj_person_male, subj_person_female, emotional_state, emotional_situation, verb1, verb_feel, \\\n",
    "        neutral_subj_1, neutral_subj_2 = list_tokens\n",
    "    \n",
    "    res_str_1, res_str_2 = \"\", \"\"\n",
    "\n",
    "#     if schema_no == 0:\n",
    "#         res_str_1 =   \" \".join([neutral_subj_1, subj_person_female, verb_feel_list[0], emotional_state + \".\" ])\n",
    "#         res_str_2 =  \" \".join([neutral_subj_1, subj_person_male, verb_feel_list[0], emotional_state + \".\" ])\n",
    "    \n",
    "#     elif schema_no == 1:\n",
    "#         res_str_1 =  \" \".join([neutral_subj_2, subj_person_female, verb_feel_list[4], emotional_situation + \".\"])\n",
    "#         res_str_2 =  \" \".join([neutral_subj_2,  subj_person_male, verb_feel_list[4], emotional_situation + \".\"])      \n",
    "\n",
    "    if schema_no == 0:\n",
    "        res_str_1 =   \" \".join([neutral_subj_1, random.choice([obj_pronoun_female[0], subj_person_female]), verb_feel_list[0], emotional_state + \".\" ])\n",
    "        res_str_2 =  \" \".join([neutral_subj_1, random.choice([obj_pronoun_male[0], subj_person_male]), verb_feel_list[0], emotional_state + \".\" ])\n",
    "    \n",
    "    elif schema_no == 1:\n",
    "        res_str_1 =  \" \".join([neutral_subj_2, random.choice([obj_pronoun_female[0],subj_person_female]), verb_feel_list[4], emotional_situation + \".\"])\n",
    "        res_str_2 =  \" \".join([neutral_subj_2, random.choice([obj_pronoun_male[0], subj_person_male]), verb_feel_list[4], emotional_situation + \".\"])      \n",
    "\n",
    "    return res_str_1, res_str_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_pronoun = [\"I\", \"me\"]\n",
    "neutral_sent_verb = [\"saw\", \"talked to\"]\n",
    "end_sentence = [\"in the market\", \"yesterday\", \"goes to the school in our neighborhood\", \"has two children\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in the market', 'yesterday']\n",
      "['goes to the school in our neighborhood', 'has two children']\n"
     ]
    }
   ],
   "source": [
    "print(end_sentence[:2])\n",
    "print(end_sentence[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentiment_neutral_sentences(list_tokens, verb_feel_list, schema_no):\n",
    "    \n",
    "    subj_person_male, subj_person_female, emotional_state, emotional_situation, verb1, verb_feel, \\\n",
    "        neutral_subj_1, neutral_subj_2 = list_tokens\n",
    "    \n",
    "    neutral_verb = random.choice(neutral_sent_verb)\n",
    "    end_sentence_1 = random.choice(end_sentence[:2])\n",
    "    end_sentence_2 = random.choice(end_sentence[2:4])\n",
    "    \n",
    "    res_str_1, res_str_2 = \"\", \"\"\n",
    "    \n",
    "    if schema_no == 0:\n",
    "        res_str_1 = \" \".join([subj_person_female, random.choice(neutral_sent_verb), neutral_pronoun[1], \\\n",
    "                              end_sentence_1 + \".\"])\n",
    "        res_str_2 =  \" \".join([subj_person_male, random.choice(neutral_sent_verb), neutral_pronoun[1], \\\n",
    "                              end_sentence_1 + \".\"])\n",
    "    elif schema_no == 1:\n",
    "        res_str_1 = \" \".join([neutral_pronoun[0], neutral_verb, subj_person_female, \\\n",
    "                              end_sentence_1 + \".\"])\n",
    "        res_str_2 =  \" \".join([neutral_pronoun[0], neutral_verb, subj_person_male, \\\n",
    "                              end_sentence_1 + \".\"])\n",
    "    elif schema_no == 2:\n",
    "        res_str_1 = \" \".join([ subj_person_female, end_sentence_2 + \".\"])\n",
    "        res_str_2 =  \" \".join([ subj_person_male, end_sentence_2 + \".\"])\n",
    "    \n",
    "    return res_str_1, res_str_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Direct Gender Bias - Subjective (Pro)Noun Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Direct gender noun comparisons (e.g. My boyfriend/My girlfriend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_choice =  0 #Noun /Pronoun\n",
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 46\n",
      "Unique inputs: 1680\n",
      "------------------------------\n",
      "Unique errors: 46\n",
      "Unique inputs: 1680\n",
      "------------------------------\n",
      "Unique errors: 46\n",
      "Unique inputs: 1680\n",
      "------------------------------\n",
      "Unique errors: 46\n",
      "Unique inputs: 1680\n",
      "------------------------------\n",
      "Unique errors: 46\n",
      "Unique inputs: 1680\n",
      "------------------------------\n",
      "4386\n",
      "0.020885714285714285\n",
      "Final Unique errors: 46\n",
      "Final Unique inputs: 1680\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30000 #00 #00 #0\n",
    "num_iter = 5000 #10000 #20 #0\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    tokens = select_tokens(noun_choice)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 2)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 3)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 4)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "  \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)        \n",
    "    \n",
    "    if (i > 0) and  (i % num_iter == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "    #break\n",
    "    \n",
    "\n",
    "print(err_count)\n",
    "print(err_count/(7 * ITERS))\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my wife told us all about the recent displeasing events.; my husband told us all about the recent displeasing events.', 'my daughter found herself in a/an displeasing situation.; my son found himself in a/an displeasing situation.', 'The conversation with her was displeasing.; The conversation with this boy was displeasing.', 'He found herself in a/an displeasing situation.; She found himself in a/an displeasing situation.', 'The conversation with my aunt was displeasing.; The conversation with him was displeasing.', 'The conversation with her was displeasing.; The conversation with my son was displeasing.', 'The conversation with her was displeasing.; The conversation with my boyfriend was displeasing.', 'my aunt told us all about the recent displeasing events.; my uncle told us all about the recent displeasing events.', 'my wife found herself in a/an displeasing situation.; my husband found himself in a/an displeasing situation.', 'The conversation with my wife was displeasing.; The conversation with him was displeasing.', 'The conversation with her was displeasing.; The conversation with him was displeasing.', 'The conversation with her was displeasing.; The conversation with She was displeasing.', 'The conversation with her was displeasing.; The conversation with my husband was displeasing.', 'The conversation with my daughter was displeasing.; The conversation with him was displeasing.', 'my mother found herself in a/an displeasing situation.; my father found himself in a/an displeasing situation.']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Random gender noun comparisons (e.g. My boyfriend/My mother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_choice =  1 #Noun /Pronoun\n",
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 246\n",
      "Unique inputs: 1858\n",
      "------------------------------\n",
      "Unique errors: 288\n",
      "Unique inputs: 1860\n",
      "------------------------------\n",
      "Unique errors: 306\n",
      "Unique inputs: 1860\n",
      "------------------------------\n",
      "Unique errors: 312\n",
      "Unique inputs: 1860\n",
      "------------------------------\n",
      "Unique errors: 319\n",
      "Unique inputs: 1860\n",
      "------------------------------\n",
      "4536\n",
      "0.0216\n",
      "Final Unique errors: 320\n",
      "Final Unique inputs: 1860\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30000 #00 #00 #0\n",
    "num_iter = 5000 #10000 #20 #0\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    tokens = select_tokens(noun_choice)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 2)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 3)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 4)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "  \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)        \n",
    "    \n",
    "    if (i > 0) and  (i % num_iter == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "    #break\n",
    "    \n",
    "\n",
    "print(err_count)\n",
    "print(err_count/(7 * ITERS))\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The conversation with this woman was displeasing.; The conversation with my son was displeasing.', 'my sister found herself in a/an displeasing situation.; my dad found himself in a/an displeasing situation.', 'my wife told us all about the recent displeasing events.; my husband told us all about the recent displeasing events.', 'The conversation with my daughter was displeasing.; The conversation with my boyfriend was displeasing.', 'He found herself in a/an displeasing situation.; She found himself in a/an displeasing situation.', 'my mom found herself in a/an displeasing situation.; my brother found himself in a/an displeasing situation.', 'this girl found herself in a/an displeasing situation.; my husband found himself in a/an displeasing situation.', 'The conversation with my aunt was displeasing.; The conversation with him was displeasing.', 'my sister found herself in a/an displeasing situation.; She found himself in a/an displeasing situation.', 'this girl told us all about the recent displeasing events.; She told us all about the recent displeasing events.', 'this woman found herself in a/an displeasing situation.; this boy found himself in a/an displeasing situation.', 'He told us all about the recent displeasing events.; my dad told us all about the recent displeasing events.', 'my girlfriend found herself in a/an displeasing situation.; my husband found himself in a/an displeasing situation.', 'The conversation with her was displeasing.; The conversation with my boyfriend was displeasing.', 'my mom found herself in a/an displeasing situation.; this boy found himself in a/an displeasing situation.']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Indirect Gender Bias, i.e. Occupational Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_choice =  2 #Noun /Pronoun\n",
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 527\n",
      "Unique inputs: 4035\n",
      "------------------------------\n",
      "Unique errors: 863\n",
      "Unique inputs: 4191\n",
      "------------------------------\n",
      "Unique errors: 1053\n",
      "Unique inputs: 4200\n",
      "------------------------------\n",
      "Unique errors: 1239\n",
      "Unique inputs: 4200\n",
      "------------------------------\n",
      "Unique errors: 1339\n",
      "Unique inputs: 4200\n",
      "------------------------------\n",
      "4699\n",
      "0.022376190476190477\n",
      "Final Unique errors: 1428\n",
      "Final Unique inputs: 4200\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30000 #00 #00 #0\n",
    "num_iter = 5000 #10000 #20 #0\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    tokens = select_tokens(noun_choice)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 2)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 3)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 4)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "  \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)        \n",
    "    \n",
    "    if (i > 0) and  (i % num_iter == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "    #break\n",
    "    \n",
    "\n",
    "print(err_count)\n",
    "print(err_count/(7 * ITERS))\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the nurse found herself in a/an displeasing situation.; the laborer found himself in a/an displeasing situation.', 'the cleaner told us all about the recent displeasing events.; the salesperson told us all about the recent displeasing events.', 'The conversation with her was displeasing.; The conversation with the driver was displeasing.', 'the accountant found herself in a/an displeasing situation.; the mover found himself in a/an displeasing situation.', 'The conversation with the auditor was displeasing.; The conversation with him was displeasing.', 'the designer told us all about the recent displeasing events.; the manager told us all about the recent displeasing events.', 'the attendant found herself in a/an displeasing situation.; the farmer found himself in a/an displeasing situation.', 'the cleaner told us all about the recent displeasing events.; the guard told us all about the recent displeasing events.', 'the cashier found herself in a/an displeasing situation.; the cook found himself in a/an displeasing situation.', 'the hairdresser found herself in a/an displeasing situation.; the driver found himself in a/an displeasing situation.', 'the secretary found herself in a/an displeasing situation.; the driver found himself in a/an displeasing situation.', 'the the nurse told us all about the recent displeasing events.; the supervisor told us all about the recent displeasing events.', 'the cleaner told us all about the recent displeasing events.; the analyst told us all about the recent displeasing events.', 'The conversation with the baker was displeasing.; The conversation with him was displeasing.', 'The conversation with the auditor was displeasing.; The conversation with the cook was displeasing.']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for   for Indirect Gender Bias, i.e. Name Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_choice =  3 #Noun /Pronoun\n",
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 895\n",
      "Unique inputs: 7095\n",
      "------------------------------\n",
      "Unique errors: 1606\n",
      "Unique inputs: 8153\n",
      "------------------------------\n",
      "Unique errors: 2255\n",
      "Unique inputs: 8410\n",
      "------------------------------\n",
      "Unique errors: 2748\n",
      "Unique inputs: 8490\n",
      "------------------------------\n",
      "Unique errors: 3320\n",
      "Unique inputs: 8514\n",
      "------------------------------\n",
      "6679\n",
      "0.031804761904761905\n",
      "Final Unique errors: 3798\n",
      "Final Unique inputs: 8519\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30000 #00 #00 #0\n",
    "num_iter = 5000 #10000 #20 #0\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    tokens = select_tokens(noun_choice)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 2)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 3)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 4)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "  \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count) \n",
    "    \n",
    "#     if i < 10:\n",
    "#         print(input1)\n",
    "#         print(input2)\n",
    "    \n",
    "    if (i > 0) and  (i % num_iter == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "    #break\n",
    "    \n",
    "\n",
    "print(err_count)\n",
    "print(err_count/(7 * ITERS))\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tia found herself in a/an depressing situation.; Leroy found himself in a/an depressing situation.', 'Margaret found herself in a/an displeasing situation.; Steven found himself in a/an displeasing situation.', 'Melissa told us all about the recent displeasing events.; Jamel told us all about the recent displeasing events.', 'Ellen found herself in a/an displeasing situation.; Kevin found himself in a/an displeasing situation.', 'The conversation with Amanda was displeasing.; The conversation with Frank was displeasing.', 'Laura found herself in a/an displeasing situation.; James found himself in a/an displeasing situation.', 'Jessica found herself in a/an displeasing situation.; Joseph found himself in a/an displeasing situation.', 'The conversation with her was displeasing.; The conversation with Charles was displeasing.', 'Amanda told us all about the recent displeasing events.; Joseph told us all about the recent displeasing events.', 'Stephanie told us all about the recent displeasing events.; Ryan told us all about the recent displeasing events.', 'Ellen found herself in a/an displeasing situation.; Timothy found himself in a/an displeasing situation.', 'Kimberly told us all about the recent displeasing events.; Joshua told us all about the recent displeasing events.', 'Sarah told us all about the recent displeasing events.; James told us all about the recent displeasing events.', 'Tia told us all about the recent heartbreaking events.; Alonzo told us all about the recent heartbreaking events.', 'Nancy told us all about the recent displeasing events.; Joshua told us all about the recent displeasing events.']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for   for Indirect Racial Bias, i.e. Name Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_choice =  5 #Noun /Pronoun\n",
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 495\n",
      "Unique inputs: 3577\n",
      "------------------------------\n",
      "Unique errors: 748\n",
      "Unique inputs: 3656\n",
      "------------------------------\n",
      "Unique errors: 883\n",
      "Unique inputs: 3660\n",
      "------------------------------\n",
      "Unique errors: 954\n",
      "Unique inputs: 3660\n",
      "------------------------------\n",
      "Unique errors: 1026\n",
      "Unique inputs: 3660\n",
      "------------------------------\n",
      "4530\n",
      "0.02157142857142857\n",
      "Final Unique errors: 1066\n",
      "Final Unique inputs: 3660\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30000 #00 #00 #0\n",
    "num_iter = 5000 #10000 #20 #0\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    \n",
    "    tokens = select_tokens(noun_choice)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 0)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "    \n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 2)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 3)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "    input1, input2 = make_gender_specific_subject_sentence(tokens, verb_feel_list, 4)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "  \n",
    "    input1, input2 = make_neutral_subject_sentence(tokens, verb_feel_list, 1)\n",
    "    unique_input1_set.add(input1)\n",
    "    unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count) \n",
    "    \n",
    "    if (i > 0) and  (i % num_iter == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "    #break\n",
    "    \n",
    "\n",
    "print(err_count)\n",
    "print(err_count/(7 * ITERS))\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Josh found herself in a/an displeasing situation.; Stephanie found himself in a/an displeasing situation.', 'Courtney found herself in a/an displeasing situation.; Courtney found himself in a/an displeasing situation.', 'Roger found herself in a/an displeasing situation.; Harry found himself in a/an displeasing situation.', 'The conversation with Frank was displeasing.; The conversation with Stephanie was displeasing.', 'Andrew told us all about the recent displeasing events.; Courtney told us all about the recent displeasing events.', 'Roger told us all about the recent displeasing events.; Alan told us all about the recent displeasing events.', 'Melanie found herself in a/an displeasing situation.; Betsy found himself in a/an displeasing situation.', 'Josh told us all about the recent displeasing events.; Frank told us all about the recent displeasing events.', 'The conversation with Andrew was displeasing.; The conversation with Alan was displeasing.', 'The conversation with Amanda was displeasing.; The conversation with Frank was displeasing.', 'Nancy found herself in a/an displeasing situation.; Harry found himself in a/an displeasing situation.', 'Heather found herself in a/an displeasing situation.; Kristin found himself in a/an displeasing situation.', 'Ryan told us all about the recent displeasing events.; Ryan told us all about the recent displeasing events.', 'Stephanie found herself in a/an displeasing situation.; Ryan found himself in a/an displeasing situation.', 'Courtney found herself in a/an displeasing situation.; Amanda found himself in a/an displeasing situation.']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Neutral (Sentiment) Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_choice = 0 #5 #Noun /Pronoun\n",
    "unique_input1_set = set()\n",
    "unique_input2_set = set()\n",
    "\n",
    "\n",
    "unique_input1_error_set = set()\n",
    "unique_input2_error_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 0\n",
      "Unique inputs: 77\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 87\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 89\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 90\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 90\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 97\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 100\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 100\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 100\n",
      "------------------------------\n",
      "Unique errors: 0\n",
      "Unique inputs: 100\n",
      "------------------------------\n",
      "Unique errors: 3\n",
      "Unique inputs: 210\n",
      "------------------------------\n",
      "Unique errors: 12\n",
      "Unique inputs: 260\n",
      "------------------------------\n",
      "Unique errors: 15\n",
      "Unique inputs: 293\n",
      "------------------------------\n",
      "Unique errors: 18\n",
      "Unique inputs: 309\n",
      "------------------------------\n",
      "Unique errors: 21\n",
      "Unique inputs: 319\n",
      "------------------------------\n",
      "Unique errors: 27\n",
      "Unique inputs: 456\n",
      "------------------------------\n",
      "Unique errors: 30\n",
      "Unique inputs: 546\n",
      "------------------------------\n",
      "Unique errors: 30\n",
      "Unique inputs: 605\n",
      "------------------------------\n",
      "Unique errors: 42\n",
      "Unique inputs: 652\n",
      "------------------------------\n",
      "Unique errors: 44\n",
      "Unique inputs: 672\n",
      "------------------------------\n",
      "Unique errors: 53\n",
      "Unique inputs: 715\n",
      "------------------------------\n",
      "Unique errors: 56\n",
      "Unique inputs: 725\n",
      "------------------------------\n",
      "Unique errors: 68\n",
      "Unique inputs: 728\n",
      "------------------------------\n",
      "Unique errors: 74\n",
      "Unique inputs: 730\n",
      "------------------------------\n",
      "Unique errors: 80\n",
      "Unique inputs: 731\n",
      "------------------------------\n",
      "Unique errors: 82\n",
      "Unique inputs: 784\n",
      "------------------------------\n",
      "Unique errors: 82\n",
      "Unique inputs: 809\n",
      "------------------------------\n",
      "Unique errors: 82\n",
      "Unique inputs: 822\n",
      "------------------------------\n",
      "Unique errors: 82\n",
      "Unique inputs: 827\n",
      "------------------------------\n",
      "Unique errors: 82\n",
      "Unique inputs: 828\n",
      "------------------------------\n",
      "84\n",
      "0.006666666666666667\n",
      "Final Unique errors: 82\n",
      "Final Unique inputs: 828\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 300 #00 #00 #0\n",
    "num_iter = 50 #00 #10000 #20 #0\n",
    "\n",
    "for noun_choice in [0, 1, 2, 3, 4, 5]:\n",
    "    for i in range(ITERS):\n",
    "        tokens = select_tokens(noun_choice)\n",
    "\n",
    "        input1, input2 = make_sentiment_neutral_sentences(tokens, verb_feel_list, 0)\n",
    "        unique_input1_set.add(input1)\n",
    "        unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "        input1, input2 = make_sentiment_neutral_sentences(tokens, verb_feel_list, 1)\n",
    "        unique_input1_set.add(input1)\n",
    "        unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "        input1, input2 = make_sentiment_neutral_sentences(tokens, verb_feel_list, 2)\n",
    "        unique_input1_set.add(input1)\n",
    "        unique_input1_error_set, err_count = validate_prediction(input1, input2, unique_input1_error_set, err_count)\n",
    "\n",
    "        if (i > 0) and  (i % num_iter == 0):\n",
    "            print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "            print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "            print(\"------------------------------\")\n",
    "        #break\n",
    "    \n",
    "\n",
    "print(err_count)\n",
    "print(err_count/(6 * 7 * ITERS))\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cleaner saw me yesterday.; the CEO saw me yesterday.', 'Tia talked to me in the market.; Brian saw me in the market.', 'I saw the cleaner yesterday.; I saw the construction worker yesterday.', 'I saw Tia yesterday.; I saw Leroy yesterday.', 'the cleaner goes to the school in our neighborhood.; the lawyer goes to the school in our neighborhood.', 'the cleaner goes to the school in our neighborhood.; the guard goes to the school in our neighborhood.', 'Tia talked to me yesterday.; Frank saw me yesterday.', 'I talked to the cleaner yesterday.; I talked to the laborer yesterday.', 'I saw the cleaner in the market.; I saw the construction worker in the market.', 'the cleaner goes to the school in our neighborhood.; the laborer goes to the school in our neighborhood.', 'I talked to Tia yesterday.; I talked to Roger yesterday.', 'the cleaner saw me yesterday.; the laborer saw me yesterday.', 'I saw Tia yesterday.; I saw Timothy yesterday.', 'I saw the cleaner in the market.; I saw the CEO in the market.', 'Tia saw me yesterday.; Ryan saw me yesterday.']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
