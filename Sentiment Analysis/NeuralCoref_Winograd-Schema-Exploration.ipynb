{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your usual SpaCy model (one of SpaCy English models)\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x12f9ca898>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You're done. You can now use NeuralCoref as you usually manipulate a SpaCy document annotations.\n",
    "doc = nlp(u'My sister has a dog. She loves him.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.has_coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[My sister: [My sister, She], a dog: [a dog, him]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My sister: [My sister, He, her]]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'My sister has a dog. He loves her.')\n",
    "a = doc._.coref_clusters\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My sister: [My sister, She, her]]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'My sister has a dog. She loves her.')\n",
    "d = doc._.coref_clusters\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a dog: [a dog, him]]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'My sister has a dog. They love him.')\n",
    "b = doc._.coref_clusters\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[My sister: [My sister, her]]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'My sister has a dog. They loves her.')\n",
    "c  = doc._.coref_clusters\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    }
   ],
   "source": [
    "if a == b == c == d:\n",
    "    print(\"X\")\n",
    "else:\n",
    "    print(\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_1 = ['supervisor',\n",
    "'janitor',\n",
    "'cook',\n",
    "'mover',\n",
    "'laborer',\n",
    "'construction worker',\n",
    "'chief',\n",
    "'developer',\n",
    "'carpenter',\n",
    "'manager',\n",
    "'lawyer',\n",
    "'farmer',\n",
    "'driver',\n",
    "'salesperson',\n",
    "'physician',\n",
    "'guard',\n",
    "'analyst',\n",
    "'mechanic',\n",
    "'sheriff',\n",
    "'CEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_2 = ['cashier',\n",
    "'teacher',\n",
    "'nurse',\n",
    "'assistant',\n",
    "'secretary',\n",
    "'auditor',\n",
    "'cleaner',\n",
    "'receptionist',\n",
    "'clerk',\n",
    "'counselor',\n",
    "'designer',\n",
    "'hairdresser',\n",
    "'attendant',\n",
    "'writer',\n",
    "'housekeeper',\n",
    "'baker',\n",
    "'accountant',\n",
    "'editor',\n",
    "'librarian',\n",
    "'tailor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list_p1 = ['asked the', 'disclosed to the', 'told the'] ## pronoun1 = ['he', 'she', 'they']\n",
    "verb_list_p2 = ['notified the', 'spoke with the'] ##  pronoun2 = ['his', 'her', 'their']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHY this mapping? subject/object/posssesive use <-> verb? up and down cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_pronoun_type (verb):\n",
    "    if (verb in verb_list_p1):\n",
    "        return ['he', 'she', 'they']\n",
    "    if (verb in verb_list_p2):\n",
    "        return ['his', 'her', 'their']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_1.extend([\"technician\", \"accountant\", \"engineer\"])\n",
    "occupations_2.extend([\"teacher\", \"librarian\", \"nurse\", \"paralegal\"])\n",
    "\n",
    "filler_conjunction = {}\n",
    "filler_conjunction[verb_list_p1[0]] = \"if \"\n",
    "filler_conjunction[verb_list_p1[1]] = \"that \"\n",
    "filler_conjunction[verb_list_p1[2]] = \"that \"\n",
    "filler_conjunction[verb_list_p2[0]] = \"that \"\n",
    "filler_conjunction[verb_list_p2[1]] = \"about \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_action = {}\n",
    "action1 = [\"can eat meat\", \"can play a ukelele\", \"can do 100 push ups\", \n",
    "           \"can generate the report\",\n",
    "           \"can bake cookies\", \"can bake bread\"]\n",
    "\n",
    "action2 = [\"could eat a sandwich\", \"could pay with cash\", \"could return the paperwork\", \n",
    "           \"could help with tax preparation\", \"could estimate how long the wait would be\",\n",
    "           \"could help with the delivery\", \"could bake a cake\", \"could sign the document\",\n",
    "           \"could bake cookies\", \"could bake bread\"]\n",
    "verb_action[verb_list_p1[0]] = [action1, action2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_action[verb_list_p1[1]] = [action1, action2]\n",
    "verb_action[verb_list_p1[2]] = [action1, action2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "action3 = ['work was unsatisfactory', 'performance was not up to the mark',\n",
    "           'application was approved', 'application was not approved',\n",
    "           'application was under review', 'work was appreciated', \n",
    "           'behaviour was unacceptable', 'project scope had been finalised']\n",
    "\n",
    "verb_action[verb_list_p2[0]] = [action3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "action4 = ['professional goals', 'personal goals',\n",
    "           'struggles with addiction', \n",
    "           'dislike for Korean cinema', 'woodworking hobby',\n",
    "           'desire to study', 'love for coffee',\n",
    "           'frustrations with work']\n",
    "verb_action[verb_list_p2[1]] = [action4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clusters(sentence):\n",
    "    output = predictor.predict(document = sentence)\n",
    "    return output['clusters'], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(x, key):\n",
    "    if(key in x.keys()):\n",
    "        x[key] += 1\n",
    "    else:\n",
    "        x[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_input1_set = set()\n",
    "unique_input1_error_set = set()\n",
    "\n",
    "occupation_pair_error = {}\n",
    "\n",
    "occupation1_error = {}\n",
    "\n",
    "occupation2_error = {}\n",
    "\n",
    "verb_error = {}\n",
    "\n",
    "action_error = {}\n",
    "\n",
    "occupation_pair_count = {}\n",
    "\n",
    "occupation1_count = {}\n",
    "\n",
    "occupation2_count = {}\n",
    "\n",
    "verb_count = {}\n",
    "\n",
    "action_count = {}\n",
    "\n",
    "#add conjuction_count and erorr\n",
    "conjuction_error = {}\n",
    "conjuction_count = {}\n",
    "\n",
    "#add pronoun_type, or pronoun count and errors\n",
    "# pronoun_type_error = {}\n",
    "# pronoun_type_count = {}\n",
    "\n",
    "# pronoun_error = {}\n",
    "# pronoun_count = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement Particle swarm optimization; or an evolutionary feedback driven approach below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My sister has  a dog. She loves him.\n",
      "[My sister: [My sister, She], a dog: [a dog, him]]\n"
     ]
    }
   ],
   "source": [
    "x1 = \"My sister\" \n",
    "x2 = \"has \" \n",
    "x3 = \"a dog.\"\n",
    "x4 = \"She loves him.\"\n",
    "x = \" \".join([x1, x2, x3, x4])\n",
    "print(x)\n",
    "\n",
    "#\n",
    "#doc = nlp(u'My sister has a dog. They love her.')\n",
    "doc= nlp(x)\n",
    "c  = doc._.coref_clusters\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The manager: [The manager, his]] [the accountant: [the accountant, her]] [the accountant: [the accountant, their]]\n",
      "The manager the accountant the accountant\n",
      "The manager notified the accountant that his application was approved\n",
      "The manager notified the accountant that her application was approved\n",
      "The manager notified the accountant that their application was approved\n",
      "[The chief: [The chief, he]] [the librarian: [the librarian, she]] [if: [if, they]]\n",
      "The chief the librarian if\n",
      "The chief asked the librarian if he can eat meat\n",
      "The chief asked the librarian if she can eat meat\n",
      "The chief asked the librarian if they can eat meat\n",
      "[The CEO: [The CEO, he]] [the clerk: [the clerk, she]] [the clerk: [the clerk, they]]\n",
      "The CEO the clerk the clerk\n",
      "The CEO told the clerk that he can bake bread\n",
      "The CEO told the clerk that she can bake bread\n",
      "The CEO told the clerk that they can bake bread\n",
      "[The lawyer: [The lawyer, he]] [the nurse: [the nurse, she]] [the nurse: [the nurse, they]]\n",
      "The lawyer the nurse the nurse\n",
      "The lawyer disclosed to the nurse that he can generate the report\n",
      "The lawyer disclosed to the nurse that she can generate the report\n",
      "The lawyer disclosed to the nurse that they can generate the report\n",
      "[The driver: [The driver, he]] [the librarian: [the librarian, she]] [the librarian: [the librarian, they]]\n",
      "The driver the librarian the librarian\n",
      "The driver disclosed to the librarian that he can bake cookies\n",
      "The driver disclosed to the librarian that she can bake cookies\n",
      "The driver disclosed to the librarian that they can bake cookies\n",
      "[The farmer: [The farmer, his]] [The farmer: [The farmer, her]] [the hairdresser: [the hairdresser, their]]\n",
      "The farmer The farmer the hairdresser\n",
      "The farmer spoke with the hairdresser about his woodworking hobby\n",
      "The farmer spoke with the hairdresser about her woodworking hobby\n",
      "The farmer spoke with the hairdresser about their woodworking hobby\n",
      "[The farmer: [The farmer, he]] [the accountant: [the accountant, she]] [the accountant: [the accountant, they]]\n",
      "The farmer the accountant the accountant\n",
      "The farmer told the accountant that he can play a ukelele\n",
      "The farmer told the accountant that she can play a ukelele\n",
      "The farmer told the accountant that they can play a ukelele\n",
      "[the librarian: [the librarian, he]] [the librarian: [the librarian, she]] [if: [if, they]]\n",
      "the librarian the librarian if\n",
      "The mover asked the librarian if he can do 100 push ups\n",
      "The mover asked the librarian if she can do 100 push ups\n",
      "The mover asked the librarian if they can do 100 push ups\n",
      "[The analyst: [The analyst, his]] [the counselor: [the counselor, her]] [The analyst: [The analyst, their]]\n",
      "The analyst the counselor The analyst\n",
      "The analyst notified the counselor that his application was approved\n",
      "The analyst notified the counselor that her application was approved\n",
      "The analyst notified the counselor that their application was approved\n",
      "[The lawyer: [The lawyer, he]] [the writer: [the writer, she]] [if: [if, they]]\n",
      "The lawyer the writer if\n",
      "The lawyer asked the writer if he can generate the report\n",
      "The lawyer asked the writer if she can generate the report\n",
      "The lawyer asked the writer if they can generate the report\n",
      "[The technician: [The technician, he]] [The technician: [The technician, she]] [the writer: [the writer, they]]\n",
      "The technician The technician the writer\n",
      "The technician disclosed to the writer that he can bake cookies\n",
      "The technician disclosed to the writer that she can bake cookies\n",
      "The technician disclosed to the writer that they can bake cookies\n",
      "[The lawyer: [The lawyer, his]] [the paralegal: [the paralegal, her]] [the paralegal: [the paralegal, their]]\n",
      "The lawyer the paralegal the paralegal\n",
      "The lawyer notified the paralegal that his performance was not up to the mark\n",
      "The lawyer notified the paralegal that her performance was not up to the mark\n",
      "The lawyer notified the paralegal that their performance was not up to the mark\n",
      "[The engineer: [The engineer, he]] [the designer: [the designer, she]] [the designer: [the designer, they]]\n",
      "The engineer the designer the designer\n",
      "The engineer asked the designer if he could eat a sandwich\n",
      "The engineer asked the designer if she could eat a sandwich\n",
      "The engineer asked the designer if they could eat a sandwich\n",
      "[The mechanic: [The mechanic, he]] [the receptionist: [the receptionist, she]] [if: [if, they]]\n",
      "The mechanic the receptionist if\n",
      "The mechanic asked the receptionist if he could pay with cash\n",
      "The mechanic asked the receptionist if she could pay with cash\n",
      "The mechanic asked the receptionist if they could pay with cash\n",
      "14\n",
      "0.4666666666666667\n",
      "Final Unique errors: 6823\n",
      "Final Unique inputs: 17979\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30 #000\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    oc1 = random.choice(occupations_1)\n",
    "    oc2 = random.choice(occupations_2)\n",
    "    verb = random.choice(list(verb_action.keys()))\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    pronoun = choose_pronoun_type(verb)\n",
    "    input1 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action \n",
    "    \n",
    "    input2 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action \n",
    "    \n",
    "    input3 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[2] + \" \" + action \n",
    "\n",
    "    inp1 = nlp(input1)    \n",
    "    pred1 = inp1._.coref_clusters\n",
    "\n",
    "    inp2 = nlp(input2)    \n",
    "    pred2 = inp2._.coref_clusters\n",
    "\n",
    "    inp3 = nlp(input3)    \n",
    "    pred3 = inp3._.coref_clusters\n",
    "\n",
    "    if (i > 0) and  (i % 10000 == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "    unique_input1_set.add(input1)\n",
    "    \n",
    "    update_dict(occupation_pair_count, (oc1, oc2))\n",
    "    update_dict(occupation1_count, oc1)\n",
    "    update_dict(occupation2_count, oc2)\n",
    "    update_dict(verb_count, verb)\n",
    "    update_dict(action_count, action)\n",
    "    update_dict(conjuction_count, filler_conjunction[verb])\n",
    "\n",
    "    if (len(pred1) > 0 and len(pred2) > 0 and len(pred3) > 0):\n",
    "        if not (str(pred1[0][0]) == str(pred2[0][0]) and str(pred2[0][0]) == str(pred3[0][0])): \n",
    "            err_count += 1\n",
    "\n",
    "            unique_input1_error_set.add(input1)\n",
    "\n",
    "            print(pred1, pred2, pred3)\n",
    "            print(pred1[0][0], pred2[0][0], pred3[0][0])\n",
    "            print(input1)\n",
    "            print(input2)\n",
    "            print(input3)\n",
    "\n",
    "            update_dict(occupation_pair_error, (oc1, oc2))\n",
    "            update_dict(occupation1_error, oc1)\n",
    "            update_dict(occupation2_error, oc2)\n",
    "            update_dict(verb_error, verb)\n",
    "            update_dict(action_error, action)\n",
    "            update_dict(conjuction_error, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "\n",
    "print(err_count)\n",
    "print(err_count/ITERS)\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 3634\n",
      "Unique inputs: 8284\n",
      "------------------------------\n",
      "Unique errors: 6194\n",
      "Unique inputs: 13940\n",
      "------------------------------\n",
      "12987\n",
      "0.4329\n",
      "Final Unique errors: 8068\n",
      "Final Unique inputs: 18006\n"
     ]
    }
   ],
   "source": [
    "err_count = 0\n",
    "ITERS = 30000\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    oc1 = random.choice(occupations_1)\n",
    "    oc2 = random.choice(occupations_2)\n",
    "    verb = random.choice(list(verb_action.keys()))\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    pronoun = choose_pronoun_type(verb)\n",
    "    input1 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action \n",
    "    \n",
    "    input2 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action \n",
    "    \n",
    "    input3 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[2] + \" \" + action \n",
    "\n",
    "    inp1 = nlp(input1)    \n",
    "    pred1 = inp1._.coref_clusters\n",
    "\n",
    "    inp2 = nlp(input2)    \n",
    "    pred2 = inp2._.coref_clusters\n",
    "\n",
    "    inp3 = nlp(input3)    \n",
    "    pred3 = inp3._.coref_clusters\n",
    "\n",
    "    if (i > 0) and  (i % 10000 == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "    unique_input1_set.add(input1)\n",
    "    \n",
    "    update_dict(occupation_pair_count, (oc1, oc2))\n",
    "    update_dict(occupation1_count, oc1)\n",
    "    update_dict(occupation2_count, oc2)\n",
    "    update_dict(verb_count, verb)\n",
    "    update_dict(action_count, action)\n",
    "    update_dict(conjuction_count, filler_conjunction[verb])\n",
    "\n",
    "    if (len(pred1) > 0 and len(pred2) > 0 and len(pred3) > 0):\n",
    "        if not (str(pred1[0][0]) == str(pred2[0][0]) and str(pred2[0][0]) == str(pred3[0][0])): \n",
    "            err_count += 1\n",
    "\n",
    "            unique_input1_error_set.add(input1)\n",
    "\n",
    "#             print(pred1, pred2, pred3)\n",
    "#             print(pred1[0][0], pred2[0][0], pred3[0][0])\n",
    "#             print(input1)\n",
    "#             print(input2)\n",
    "#             print(input3)\n",
    "\n",
    "            update_dict(occupation_pair_error, (oc1, oc2))\n",
    "            update_dict(occupation1_error, oc1)\n",
    "            update_dict(occupation2_error, oc2)\n",
    "            update_dict(verb_error, verb)\n",
    "            update_dict(action_error, action)\n",
    "            update_dict(conjuction_error, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "\n",
    "print(err_count)\n",
    "print(err_count/ITERS)\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The lawyer disclosed to the auditor that he can bake bread', 'The guard told the baker that he could return the paperwork', 'The physician asked the cleaner if he could sign the document', 'The mover asked the attendant if he can bake cookies', 'The analyst disclosed to the auditor that he could estimate how long the wait would be', 'The analyst disclosed to the counselor that he could sign the document', 'The guard asked the clerk if he could return the paperwork', 'The supervisor told the designer that he can do 100 push ups', 'The CEO notified the housekeeper that his behaviour was unacceptable', 'The engineer asked the editor if he can generate the report']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_input1_set = set()\n",
    "unique_input1_error_set = set()\n",
    "\n",
    "occupation_pair_error = {}\n",
    "\n",
    "occupation1_error = {}\n",
    "\n",
    "occupation2_error = {}\n",
    "\n",
    "verb_error = {}\n",
    "\n",
    "action_error = {}\n",
    "\n",
    "occupation_pair_count = {}\n",
    "\n",
    "occupation1_count = {}\n",
    "\n",
    "occupation2_count = {}\n",
    "\n",
    "verb_count = {}\n",
    "\n",
    "action_count = {}\n",
    "\n",
    "#add conjuction_count and erorr\n",
    "conjuction_error = {}\n",
    "conjuction_count = {}\n",
    "\n",
    "#add pronoun_type, or pronoun count and errors\n",
    "# pronoun_type_error = {}\n",
    "# pronoun_type_count = {}\n",
    "\n",
    "# pronoun_error = {}\n",
    "# pronoun_count = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique errors: 3128\n",
      "Unique inputs: 8209\n",
      "------------------------------\n",
      "Unique errors: 5277\n",
      "Unique inputs: 13901\n",
      "------------------------------\n",
      "11398\n",
      "0.37993333333333335\n",
      "Final Unique errors: 6816\n",
      "Final Unique inputs: 17966\n"
     ]
    }
   ],
   "source": [
    "# TEST without neutral pronoun - \"they\"\n",
    "\n",
    "err_count = 0\n",
    "ITERS = 0\n",
    "ITERS = 30000\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    oc1 = random.choice(occupations_1)\n",
    "    oc2 = random.choice(occupations_2)\n",
    "    verb = random.choice(list(verb_action.keys()))\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    pronoun = choose_pronoun_type(verb)\n",
    "    input1 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action \n",
    "    \n",
    "    input2 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action \n",
    "    \n",
    "    inp1 = nlp(input1)    \n",
    "    pred1 = inp1._.coref_clusters\n",
    "\n",
    "    inp2 = nlp(input2)    \n",
    "    pred2 = inp2._.coref_clusters\n",
    "\n",
    "    if (i > 0) and (i % 10000 == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "    unique_input1_set.add(input1)\n",
    "    \n",
    "    update_dict(occupation_pair_count, (oc1, oc2))\n",
    "    update_dict(occupation1_count, oc1)\n",
    "    update_dict(occupation2_count, oc2)\n",
    "    update_dict(verb_count, verb)\n",
    "    update_dict(action_count, action)\n",
    "    update_dict(conjuction_count, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "    if (len(pred1) > 0 and len(pred2) > 0):\n",
    "        if not (str(pred1[0][0]) == str(pred2[0][0])):\n",
    "            err_count += 1\n",
    "\n",
    "            unique_input1_error_set.add(input1)\n",
    "\n",
    "#             print(pred1, pred2) \n",
    "#             print(pred1[0][0], pred2[0][0]) \n",
    "#             print(input1)\n",
    "#             print(input2)\n",
    "\n",
    "            update_dict(occupation_pair_error, (oc1, oc2))\n",
    "            update_dict(occupation1_error, oc1)\n",
    "            update_dict(occupation2_error, oc2)\n",
    "            update_dict(verb_error, verb)\n",
    "            update_dict(action_error, action)\n",
    "            update_dict(conjuction_error, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "\n",
    "print(err_count)\n",
    "print(err_count/ITERS)\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The lawyer: [The lawyer, his]] [the teacher: [the teacher, her]]\n",
      "The lawyer the teacher\n",
      "The lawyer spoke with the teacher about his personal goals\n",
      "The lawyer spoke with the teacher about her personal goals\n",
      "[The lawyer: [The lawyer, he]] [the secretary: [the secretary, she]]\n",
      "The lawyer the secretary\n",
      "The lawyer disclosed to the secretary that he can bake cookies\n",
      "The lawyer disclosed to the secretary that she can bake cookies\n",
      "[The laborer: [The laborer, his]] [the paralegal: [the paralegal, her]]\n",
      "The laborer the paralegal\n",
      "The laborer notified the paralegal that his performance was not up to the mark\n",
      "The laborer notified the paralegal that her performance was not up to the mark\n",
      "[The engineer: [The engineer, he]] [the accountant: [the accountant, she]]\n",
      "The engineer the accountant\n",
      "The engineer told the accountant that he can bake cookies\n",
      "The engineer told the accountant that she can bake cookies\n",
      "[The physician: [The physician, he]] [the baker: [the baker, she]]\n",
      "The physician the baker\n",
      "The physician asked the baker if he can play a ukelele\n",
      "The physician asked the baker if she can play a ukelele\n",
      "[The carpenter: [The carpenter, he]] [the paralegal: [the paralegal, she]]\n",
      "The carpenter the paralegal\n",
      "The carpenter told the paralegal that he can play a ukelele\n",
      "The carpenter told the paralegal that she can play a ukelele\n",
      "[The sheriff: [The sheriff, he]] [the nurse: [the nurse, she]]\n",
      "The sheriff the nurse\n",
      "The sheriff asked the nurse if he could bake a cake\n",
      "The sheriff asked the nurse if she could bake a cake\n",
      "[The lawyer: [The lawyer, he]] [the designer: [the designer, she]]\n",
      "The lawyer the designer\n",
      "The lawyer asked the designer if he can eat meat\n",
      "The lawyer asked the designer if she can eat meat\n",
      "[The laborer: [The laborer, he]] [the cashier: [the cashier, she]]\n",
      "The laborer the cashier\n",
      "The laborer asked the cashier if he can bake cookies\n",
      "The laborer asked the cashier if she can bake cookies\n",
      "[the accountant: [the accountant, he]] [The construction worker: [The construction worker, she]]\n",
      "the accountant The construction worker\n",
      "The construction worker told the accountant that he could pay with cash\n",
      "The construction worker told the accountant that she could pay with cash\n",
      "[The carpenter: [The carpenter, he]] [the teacher: [the teacher, she]]\n",
      "The carpenter the teacher\n",
      "The carpenter disclosed to the teacher that he can bake bread\n",
      "The carpenter disclosed to the teacher that she can bake bread\n",
      "[The CEO: [The CEO, his]] [the teacher: [the teacher, her]]\n",
      "The CEO the teacher\n",
      "The CEO spoke with the teacher about his woodworking hobby\n",
      "The CEO spoke with the teacher about her woodworking hobby\n",
      "12\n",
      "0.4\n",
      "Final Unique errors: 6827\n",
      "Final Unique inputs: 17990\n"
     ]
    }
   ],
   "source": [
    "# TEST without neutral pronoun - \"they\"\n",
    "\n",
    "err_count = 0\n",
    "ITERS = 0\n",
    "ITERS = 30 #000\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    oc1 = random.choice(occupations_1)\n",
    "    oc2 = random.choice(occupations_2)\n",
    "    verb = random.choice(list(verb_action.keys()))\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    pronoun = choose_pronoun_type(verb)\n",
    "    input1 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action \n",
    "    \n",
    "    input2 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action \n",
    "    \n",
    "    inp1 = nlp(input1)    \n",
    "    pred1 = inp1._.coref_clusters\n",
    "\n",
    "    inp2 = nlp(input2)    \n",
    "    pred2 = inp2._.coref_clusters\n",
    "\n",
    "    if (i > 0) and (i % 10000 == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "    unique_input1_set.add(input1)\n",
    "    \n",
    "    update_dict(occupation_pair_count, (oc1, oc2))\n",
    "    update_dict(occupation1_count, oc1)\n",
    "    update_dict(occupation2_count, oc2)\n",
    "    update_dict(verb_count, verb)\n",
    "    update_dict(action_count, action)\n",
    "    update_dict(conjuction_count, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "    if (len(pred1) > 0 and len(pred2) > 0):\n",
    "        if not (str(pred1[0][0]) == str(pred2[0][0])):\n",
    "            err_count += 1\n",
    "\n",
    "            unique_input1_error_set.add(input1)\n",
    "\n",
    "            print(pred1, pred2) \n",
    "            print(pred1[0][0], pred2[0][0]) \n",
    "            print(input1)\n",
    "            print(input2)\n",
    "\n",
    "            update_dict(occupation_pair_error, (oc1, oc2))\n",
    "            update_dict(occupation1_error, oc1)\n",
    "            update_dict(occupation2_error, oc2)\n",
    "            update_dict(verb_error, verb)\n",
    "            update_dict(action_error, action)\n",
    "            update_dict(conjuction_error, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "\n",
    "print(err_count)\n",
    "print(err_count/ITERS)\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The cook: [The cook, his]] [the baker: [the baker, her]]\n",
      "The cook the baker\n",
      "The cook notified the baker that his work was appreciated\n",
      "The cook notified the baker that her work was appreciated\n",
      "[The chief: [The chief, his]] [the accountant: [the accountant, her]]\n",
      "The chief the accountant\n",
      "The chief notified the accountant that his performance was not up to the mark\n",
      "The chief notified the accountant that her performance was not up to the mark\n",
      "[The CEO: [The CEO, he]] [the tailor: [the tailor, she]]\n",
      "The CEO the tailor\n",
      "The CEO asked the tailor if he can generate the report\n",
      "The CEO asked the tailor if she can generate the report\n",
      "[the accountant: [the accountant, his]] [The construction worker: [The construction worker, her]]\n",
      "the accountant The construction worker\n",
      "The construction worker spoke with the accountant about his love for coffee\n",
      "The construction worker spoke with the accountant about her love for coffee\n",
      "[The manager: [The manager, he]] [the librarian: [the librarian, she]]\n",
      "The manager the librarian\n",
      "The manager told the librarian that he can bake cookies\n",
      "The manager told the librarian that she can bake cookies\n",
      "[The engineer: [The engineer, he]] [the accountant: [the accountant, she]]\n",
      "The engineer the accountant\n",
      "The engineer told the accountant that he can eat meat\n",
      "The engineer told the accountant that she can eat meat\n",
      "[The farmer: [The farmer, his]] [the secretary: [the secretary, her]]\n",
      "The farmer the secretary\n",
      "The farmer notified the secretary that his application was under review\n",
      "The farmer notified the secretary that her application was under review\n",
      "[The laborer: [The laborer, he]] [the secretary: [the secretary, she]]\n",
      "The laborer the secretary\n",
      "The laborer asked the secretary if he could sign the document\n",
      "The laborer asked the secretary if she could sign the document\n",
      "8\n",
      "0.26666666666666666\n",
      "Final Unique errors: 6829\n",
      "Final Unique inputs: 18001\n"
     ]
    }
   ],
   "source": [
    "# TEST without neutral pronoun - \"they\"\n",
    "\n",
    "err_count = 0\n",
    "ITERS = 0\n",
    "ITERS = 30 #000\n",
    "\n",
    "\n",
    "for i in range(ITERS):\n",
    "    oc1 = random.choice(occupations_1)\n",
    "    oc2 = random.choice(occupations_2)\n",
    "    verb = random.choice(list(verb_action.keys()))\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    pronoun = choose_pronoun_type(verb)\n",
    "    input1 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action \n",
    "    \n",
    "    input2 = \"The \" + oc1 + \" \" + verb + \" \" + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action \n",
    "    \n",
    "    inp1 = nlp(input1)    \n",
    "    pred1 = inp1._.coref_clusters\n",
    "\n",
    "    inp2 = nlp(input2)    \n",
    "    pred2 = inp2._.coref_clusters\n",
    "\n",
    "    if (i > 0) and (i % 10000 == 0):\n",
    "        print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "        print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "    unique_input1_set.add(input1)\n",
    "    \n",
    "    update_dict(occupation_pair_count, (oc1, oc2))\n",
    "    update_dict(occupation1_count, oc1)\n",
    "    update_dict(occupation2_count, oc2)\n",
    "    update_dict(verb_count, verb)\n",
    "    update_dict(action_count, action)\n",
    "    update_dict(conjuction_count, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "    #if (len(pred1) > 0 and len(pred2) > 0):\n",
    "    if not (str(pred1[0][0]) == str(pred2[0][0])):\n",
    "        err_count += 1\n",
    "\n",
    "        unique_input1_error_set.add(input1)\n",
    "\n",
    "        print(pred1, pred2) \n",
    "        print(pred1[0][0], pred2[0][0]) \n",
    "        print(input1)\n",
    "        print(input2)\n",
    "\n",
    "        update_dict(occupation_pair_error, (oc1, oc2))\n",
    "        update_dict(occupation1_error, oc1)\n",
    "        update_dict(occupation2_error, oc2)\n",
    "        update_dict(verb_error, verb)\n",
    "        update_dict(action_error, action)\n",
    "        update_dict(conjuction_error, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "\n",
    "print(err_count)\n",
    "print(err_count/ITERS)\n",
    "print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The mover asked the attendant if he can bake cookies', 'The farmer notified the housekeeper that his work was unsatisfactory', 'The CEO notified the housekeeper that his behaviour was unacceptable', 'The construction worker spoke with the librarian about his desire to study', 'The engineer asked the editor if he can generate the report', 'The chief disclosed to the teacher that he can do 100 push ups', 'The lawyer asked the teacher if he can generate the report', 'The mechanic told the receptionist that he can generate the report', 'The physician asked the nurse if he could help with tax preparation', 'The driver asked the baker if he can eat meat']\n"
     ]
    }
   ],
   "source": [
    "print(list(unique_input1_error_set)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_count = 0\n",
    "# ITERS = 300 #30000\n",
    "\n",
    "\n",
    "# for i in range(ITERS):\n",
    "#     oc1 = random.choice(occupations_1)\n",
    "#     oc2 = random.choice(occupations_2)\n",
    "#     verb = random.choice(list(verb_action.keys()))\n",
    "#     action = random.choice(random.choice(verb_action[verb]))\n",
    "#     pronoun = choose_pronoun_type(verb)\n",
    "#     input1 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action) \n",
    "    \n",
    "#     input2 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action) \n",
    "    \n",
    "#     input3 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[2] + \" \" + action) \n",
    "#     pred1, _ = predict_clusters(input1)\n",
    "#     pred2, _ = predict_clusters(input2)\n",
    "#     #pred3, _ = predict_clusters(input2)\n",
    "#     pred3, _ = predict_clusters(input3)\n",
    "    \n",
    "    \n",
    "# #     if(i > 0) and \n",
    "#     if (i % 30 == 0):\n",
    "#         print(\"Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "#         print(\"Unique inputs: \" + str(len(unique_input1_set)))\n",
    "#         print(\"------------------------------\")\n",
    "        \n",
    "        \n",
    "#     unique_input1_set.add(input1)\n",
    "    \n",
    "#     update_dict(occupation_pair_count, (oc1, oc2))\n",
    "#     update_dict(occupation1_count, oc1)\n",
    "#     update_dict(occupation2_count, oc2)\n",
    "#     update_dict(verb_count, verb)\n",
    "#     update_dict(action_count, action)\n",
    "#     update_dict(conjuction_count, filler_conjunction[verb])\n",
    "\n",
    "    \n",
    "\n",
    "#     if not (pred1 == pred2 and pred2 == pred3):\n",
    "#         if (len(pred1) > 0 and len(pred2) > 0 and len(pred3) > 0):\n",
    "#             if (len(pred1[0]) == len(pred2[0]) and len(pred2[0]) == len(pred3[0]) ):\n",
    "# #         if(True):\n",
    "#                 err_count += 1\n",
    "                \n",
    "#                 unique_input1_error_set.add(input1)\n",
    "                \n",
    "# #                 print(pred1, pred2, pred3)\n",
    "# #                 print(input1)\n",
    "# #                 print(input2)\n",
    "# #                 print(input3)\n",
    "                \n",
    "#                 update_dict(occupation_pair_error, (oc1, oc2))\n",
    "#                 update_dict(occupation1_error, oc1)\n",
    "#                 update_dict(occupation2_error, oc2)\n",
    "#                 update_dict(verb_error, verb)\n",
    "#                 update_dict(action_error, action)\n",
    "#                 update_dict(conjuction_error, filler_conjunction[verb])\n",
    "\n",
    "\n",
    "\n",
    "# print(err_count)\n",
    "# print(err_count/ITERS)\n",
    "# print(\"Final Unique errors: \" + str(len(unique_input1_error_set)))\n",
    "# print(\"Final Unique inputs: \" + str(len(unique_input1_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You're done. You can now use NeuralCoref the same way you usually manipulate a SpaCy document and it's annotations.\n",
    "# doc = nlp(u'My sister has a dog. She loves him.')\n",
    "\n",
    "# doc._.has_coref\n",
    "# doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(occupation_pair_count)\n",
    "# print(occupation1_count)\n",
    "# print(occupation2_count)\n",
    "# print(verb_count)\n",
    "# print(action_count)\n",
    "# print(conjuction_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('guard', 'librarian'): 1, ('physician', 'auditor'): 2, ('supervisor', 'auditor'): 1, ('technician', 'nurse'): 1, ('cook', 'attendant'): 1, ('farmer', 'housekeeper'): 1, ('physician', 'housekeeper'): 1, ('sheriff', 'tailor'): 1, ('analyst', 'assistant'): 1, ('accountant', 'nurse'): 1, ('carpenter', 'nurse'): 1, ('manager', 'tailor'): 1, ('physician', 'assistant'): 1, ('manager', 'clerk'): 1, ('lawyer', 'clerk'): 1, ('CEO', 'editor'): 1, ('guard', 'housekeeper'): 1, ('engineer', 'nurse'): 1, ('chief', 'librarian'): 1, ('engineer', 'accountant'): 1, ('technician', 'baker'): 2, ('carpenter', 'counselor'): 2, ('guard', 'paralegal'): 1, ('construction worker', 'baker'): 1, ('manager', 'auditor'): 1, ('physician', 'nurse'): 2, ('physician', 'librarian'): 1, ('technician', 'hairdresser'): 1, ('physician', 'tailor'): 1, ('mover', 'housekeeper'): 1, ('analyst', 'attendant'): 2, ('analyst', 'accountant'): 1, ('manager', 'hairdresser'): 1, ('guard', 'clerk'): 1, ('chief', 'hairdresser'): 1, ('mechanic', 'housekeeper'): 1, ('CEO', 'nurse'): 2, ('mechanic', 'secretary'): 1, ('CEO', 'librarian'): 3, ('developer', 'hairdresser'): 1, ('laborer', 'librarian'): 1, ('mover', 'auditor'): 1, ('supervisor', 'cashier'): 2, ('cook', 'librarian'): 3, ('mover', 'secretary'): 1, ('mechanic', 'receptionist'): 2, ('carpenter', 'accountant'): 1, ('mechanic', 'nurse'): 2, ('manager', 'designer'): 1, ('chief', 'designer'): 1, ('carpenter', 'baker'): 1, ('supervisor', 'librarian'): 1, ('manager', 'writer'): 1, ('farmer', 'nurse'): 1, ('lawyer', 'secretary'): 1, ('janitor', 'librarian'): 1, ('mover', 'hairdresser'): 1, ('chief', 'writer'): 1, ('accountant', 'designer'): 1, ('salesperson', 'accountant'): 1, ('manager', 'accountant'): 1, ('chief', 'teacher'): 2, ('CEO', 'teacher'): 1, ('guard', 'receptionist'): 1, ('laborer', 'clerk'): 1, ('chief', 'baker'): 4, ('lawyer', 'receptionist'): 1, ('supervisor', 'nurse'): 2, ('engineer', 'housekeeper'): 1, ('driver', 'nurse'): 1, ('construction worker', 'secretary'): 1, ('cook', 'writer'): 1, ('technician', 'housekeeper'): 1, ('carpenter', 'teacher'): 2, ('CEO', 'writer'): 1, ('construction worker', 'paralegal'): 2, ('farmer', 'counselor'): 3, ('technician', 'teacher'): 1, ('salesperson', 'librarian'): 1, ('lawyer', 'baker'): 1, ('analyst', 'librarian'): 2, ('engineer', 'attendant'): 1, ('accountant', 'attendant'): 1, ('laborer', 'receptionist'): 1, ('manager', 'paralegal'): 1, ('manager', 'counselor'): 1, ('physician', 'teacher'): 1, ('mechanic', 'hairdresser'): 2, ('supervisor', 'writer'): 1, ('technician', 'librarian'): 1, ('chief', 'counselor'): 2, ('supervisor', 'baker'): 1, ('CEO', 'designer'): 1, ('physician', 'paralegal'): 1, ('salesperson', 'editor'): 1, ('CEO', 'baker'): 1, ('construction worker', 'nurse'): 1, ('mechanic', 'librarian'): 2, ('sheriff', 'baker'): 1, ('guard', 'baker'): 1, ('carpenter', 'secretary'): 2, ('carpenter', 'receptionist'): 1, ('manager', 'cashier'): 1, ('lawyer', 'nurse'): 1, ('mechanic', 'designer'): 1, ('accountant', 'paralegal'): 1, ('manager', 'baker'): 1, ('lawyer', 'paralegal'): 1, ('engineer', 'receptionist'): 1, ('driver', 'paralegal'): 1, ('driver', 'teacher'): 1, ('driver', 'writer'): 1, ('accountant', 'counselor'): 2, ('driver', 'receptionist'): 1, ('driver', 'baker'): 1, ('analyst', 'writer'): 1, ('chief', 'clerk'): 1, ('analyst', 'counselor'): 1, ('engineer', 'teacher'): 1, ('laborer', 'writer'): 1, ('CEO', 'receptionist'): 1, ('construction worker', 'writer'): 2, ('farmer', 'teacher'): 1, ('farmer', 'librarian'): 1, ('lawyer', 'teacher'): 1, ('salesperson', 'baker'): 1, ('lawyer', 'assistant'): 1, ('construction worker', 'accountant'): 1, ('farmer', 'writer'): 1, ('accountant', 'writer'): 1, ('lawyer', 'hairdresser'): 1}\n",
      "{'guard': 6, 'physician': 10, 'supervisor': 8, 'technician': 7, 'cook': 5, 'farmer': 8, 'sheriff': 2, 'analyst': 8, 'accountant': 7, 'carpenter': 10, 'manager': 11, 'lawyer': 9, 'CEO': 11, 'engineer': 6, 'chief': 13, 'construction worker': 8, 'mover': 4, 'mechanic': 11, 'developer': 1, 'laborer': 4, 'janitor': 1, 'salesperson': 4, 'driver': 6}\n",
      "{'librarian': 19, 'auditor': 5, 'nurse': 16, 'attendant': 5, 'housekeeper': 7, 'tailor': 3, 'assistant': 3, 'clerk': 5, 'editor': 2, 'accountant': 6, 'baker': 16, 'counselor': 11, 'paralegal': 8, 'hairdresser': 8, 'secretary': 6, 'cashier': 3, 'receptionist': 9, 'designer': 5, 'writer': 12, 'teacher': 11}\n",
      "{'told the': 45, 'disclosed to the': 22, 'spoke with the': 15, 'notified the': 39, 'asked the': 39}\n",
      "{'could bake bread': 4, 'could return the paperwork': 5, 'dislike for Korean cinema': 3, 'work was appreciated': 8, 'can bake bread': 12, 'application was under review': 6, 'could eat a sandwich': 5, 'could help with the delivery': 10, 'can generate the report': 12, 'work was unsatisfactory': 6, 'can eat meat': 8, 'can play a ukelele': 7, 'can bake cookies': 10, 'could sign the document': 4, 'could help with tax preparation': 5, 'can do 100 push ups': 7, 'could pay with cash': 7, 'could bake cookies': 5, 'application was approved': 9, 'performance was not up to the mark': 6, 'could bake a cake': 4, 'personal goals': 1, 'desire to study': 1, 'struggles with addiction': 1, 'frustrations with work': 5, 'professional goals': 1, 'could estimate how long the wait would be': 1, 'application was not approved': 2, 'project scope had been finalised': 1, 'love for coffee': 1, 'woodworking hobby': 2, 'behaviour was unacceptable': 1}\n",
      "{'that ': 106, 'about ': 15, 'if ': 39}\n"
     ]
    }
   ],
   "source": [
    "print(occupation_pair_error)\n",
    "print(occupation1_error)\n",
    "print(occupation2_error)\n",
    "print(verb_error)\n",
    "print(action_error)\n",
    "print(conjuction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_pickles/Exploration/unique_input1_set.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-97ccb1921b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_pickles/Exploration/unique_input1_set.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_input1_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_pickles/Exploration/unique_input1_set.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('saved_pickles/Exploration/unique_input1_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(unique_input1_set, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/unique_input1_error_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(unique_input1_error_set, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_pickles/Exploration/occupation_pair_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation_pair_count, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation1_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation1_count, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation2_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation2_count, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/verb_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(verb_count, handle)\n",
    "\n",
    "with open('saved_pickles/Exploration/action_count.pickle', 'wb') as handle:\n",
    "    pickle.dump(action_count, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_pickles/Exploration/occupation_pair_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation_pair_error, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation1_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation1_error, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/occupation2_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation2_error, handle)\n",
    "    \n",
    "with open('saved_pickles/Exploration/verb_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(verb_error, handle)\n",
    "\n",
    "with open('saved_pickles/Exploration/action_error.pickle', 'wb') as handle:\n",
    "    pickle.dump(action_error, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 if((oc1, oc2) in occupation_pair_error.keys()):\n",
    "#                     occupation_pair_error[(oc1, oc2)] += 1\n",
    "#                 else:\n",
    "#                     occupation_pair_error[(oc1, oc2)] = 1\n",
    "                                          \n",
    "#                 if(oc1 in occupation1_error.keys()):\n",
    "#                     occupation1_error[oc1] += 1\n",
    "#                 else:\n",
    "#                     occupation1_error[oc1] = 1\n",
    "                \n",
    "#                 if(oc2 in occupation2_error.keys()):\n",
    "#                     occupation2_error[oc1] += 1\n",
    "#                 else:\n",
    "#                     occupation2_error[oc1] = 1\n",
    "                                          \n",
    "#                 if(verb in verb_error.keys()):\n",
    "#                     verb_error[verb] += 1\n",
    "#                 else:\n",
    "#                     verb_error[verb] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_clusters(sentence):\n",
    "#     output = predictor.predict(document = sentence)\n",
    "#     return output['clusters'], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_clusters(\"The guard spoke with the librarian about his struggles with addiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_count = 0\n",
    "# ITERS = 20\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(ITERS):\n",
    "#     oc1 = random.choice(occupations_1)\n",
    "#     oc2 = random.choice(occupations_2)\n",
    "#     verb = random.choice(list(verb_action.keys()))\n",
    "#     action = random.choice(random.choice(verb_action[verb]))\n",
    "#     in1 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[0] + \" \" + action) \n",
    "    \n",
    "#     in2 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[1] + \" \" + action) \n",
    "    \n",
    "#     in3 = (\"The \" + oc1 + \" \" + verb + \" \"\n",
    "#            + oc2 + \" \" + filler_conjunction[verb] +  pronoun[2] + \" \" + action) \n",
    "#     pred1, _ = predict_clusters(in1)\n",
    "#     pred2, _ = predict_clusters(in2)\n",
    "#     pred3, _ = predict_clusters(in2)\n",
    "    \n",
    "#     if not (pred1 == pred2 and pred2 == pred3):\n",
    "#         if (len(pred1) > 0 and len(pred2) > 0 and len(pred3) > 0):\n",
    "#             err_count += 1\n",
    "\n",
    "#             print(pred1, pred2, pred3)\n",
    "#             print(in1)\n",
    "#             print(in2)\n",
    "#             print(in3)\n",
    "#             print()\n",
    "    \n",
    "\n",
    "# print(err_count)\n",
    "# print(err_count/ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
