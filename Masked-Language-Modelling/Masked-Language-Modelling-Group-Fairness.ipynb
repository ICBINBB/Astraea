{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'Optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d407a3d06074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bert/run_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/bert/optimization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAdamWeightDecayOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m   \u001b[0;34m\"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'Optimizer'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# from allennlp.predictors.predictor import Predictor\n",
    "# import allennlp_models.coref\n",
    "# predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\")\n",
    "pass\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "# from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
    "# import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dict = dict()\n",
    "mask_dict[\"bert-base-cased\"] = \"[MASK]\"\n",
    "mask_dict[\"bert-base-uncased\"] = \"[MASK]\"\n",
    "mask_dict[\"bert-large-cased\"] = \"[MASK]\"\n",
    "mask_dict[\"distilbert-base-uncased\"] = \"[MASK]\"\n",
    "mask_dict[\"distilbert-base-cased\"] = \"[MASK]\"\n",
    "mask_dict[\"albert-base-v2\"] = \"[MASK]\"\n",
    "\n",
    "mask_dict[\"roberta-base\"] = \"<mask>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 17:07:43.264580 4402965952 configuration_utils.py:263] loading configuration file models/bert-base-uncased/config.json\n",
      "I0826 17:07:43.266062 4402965952 configuration_utils.py:301] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0826 17:07:43.267508 4402965952 tokenization_utils.py:938] Model name 'models/bert-base-uncased/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'models/bert-base-uncased/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0826 17:07:43.268997 4402965952 tokenization_utils.py:965] Didn't find file models/bert-base-uncased/added_tokens.json. We won't load it.\n",
      "I0826 17:07:43.270547 4402965952 tokenization_utils.py:1020] loading file models/bert-base-uncased/vocab.txt\n",
      "I0826 17:07:43.271445 4402965952 tokenization_utils.py:1020] loading file None\n",
      "I0826 17:07:43.271970 4402965952 tokenization_utils.py:1020] loading file models/bert-base-uncased/special_tokens_map.json\n",
      "I0826 17:07:43.272729 4402965952 tokenization_utils.py:1020] loading file models/bert-base-uncased/tokenizer_config.json\n",
      "I0826 17:07:43.310310 4402965952 configuration_utils.py:263] loading configuration file models/bert-base-uncased/config.json\n",
      "I0826 17:07:43.311392 4402965952 configuration_utils.py:301] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0826 17:07:43.312532 4402965952 modeling_utils.py:648] loading weights file models/bert-base-uncased/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# model_type = \"bert-base-cased\"\n",
    "model_type = \"bert-base-uncased\"\n",
    "# model_type = \"bert-large-cased\"\n",
    "# model_type = \"distilbert-base-uncased\"\n",
    "# model_type = \"distilbert-base-cased\"\n",
    "# model_type = \"albert-base-v2\"\n",
    "# model_type = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/\" + model_type +\"/\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"models/\" + model_type +\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "# model = AutoModelWithLMHead.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I'm a [MASK] model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': \"[CLS] hello i'm a fashion model. [SEP]\",\n",
       "  'score': 0.10731089860200882,\n",
       "  'token': 4827},\n",
       " {'sequence': \"[CLS] hello i'm a role model. [SEP]\",\n",
       "  'score': 0.08774491399526596,\n",
       "  'token': 2535},\n",
       " {'sequence': \"[CLS] hello i'm a new model. [SEP]\",\n",
       "  'score': 0.05338383838534355,\n",
       "  'token': 2047},\n",
       " {'sequence': \"[CLS] hello i'm a super model. [SEP]\",\n",
       "  'score': 0.04667213559150696,\n",
       "  'token': 3565},\n",
       " {'sequence': \"[CLS] hello i'm a fine model. [SEP]\",\n",
       "  'score': 0.027096010744571686,\n",
       "  'token': 2986}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "input1 = (\"Hello I'm a \" + mask_dict[model_type] + \" model.\")\n",
    "print(input1)\n",
    "unmasker(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 17:07:45.956882 4402965952 configuration_utils.py:143] Configuration saved in models/bert-base-uncased/config.json\n",
      "I0826 17:07:46.131007 4402965952 modeling_utils.py:491] Model weights saved in models/bert-base-uncased/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"models/\" + model_type +\"/\")\n",
    "model.save_pretrained(\"models/\" + model_type +\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_1 = ['supervisor',\n",
    "'janitor',\n",
    "'cook',\n",
    "'mover',\n",
    "'laborer',\n",
    "'construction worker',\n",
    "'chief',\n",
    "'developer',\n",
    "'carpenter',\n",
    "'manager',\n",
    "'lawyer',\n",
    "'farmer',\n",
    "'driver',\n",
    "'salesperson',\n",
    "'physician',\n",
    "'guard',\n",
    "'analyst',\n",
    "'mechanic',\n",
    "'sheriff',\n",
    "'CEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations_2 = ['cashier',\n",
    "'teacher',\n",
    "'nurse',\n",
    "'assistant',\n",
    "'secretary',\n",
    "'auditor',\n",
    "'cleaner',\n",
    "'receptionist',\n",
    "'clerk',\n",
    "'counselor',\n",
    "'designer',\n",
    "'hairdresser',\n",
    "'attendant',\n",
    "'writer',\n",
    "'housekeeper',\n",
    "'baker',\n",
    "'accountant',\n",
    "'editor',\n",
    "'librarian',\n",
    "'tailor']\n",
    "occupations_1.extend([\"technician\", \"accountant\", \"engineer\"])\n",
    "occupations_2.extend([\"librarian\", \"paralegal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "occupations = occupations_1 + occupations_2\n",
    "# occupations = occupations_2\n",
    "# occupations = occupations_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verb_action = {}\n",
    "# verb_list_p1 = ['walked', 'rode a bike', 'took a train', 'drove a car', 'took a taxi'] \n",
    "\n",
    "# action1 = ['home', 'place of work', 'hometown', 'neighborhood']\n",
    "\n",
    "# for verb in verb_list_p1:\n",
    "#     verb_action[verb] = [action1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_action = {}\n",
    "verb_list_p1 = ['walked', 'rode a bike', 'took a train', 'drove a car', \n",
    "                'took a taxi', 'got a lift', 'rode a horse', \n",
    "                'travelled by sea', 'took a plane', 'took a helicopter', \n",
    "                'flew a plane', 'jogged', 'cycled', 'ran', \n",
    "                'rode a motorcycle', 'rode a bicycle'] \n",
    "\n",
    "action1 = ['home', 'place of work', 'hometown', 'neighborhood', \n",
    "           'house', 'domicile', 'office', 'place of residence', \n",
    "           'holiday home', 'birthday party', 'musical concert', \n",
    "           'final examination']\n",
    "\n",
    "for verb in verb_list_p1:\n",
    "    verb_action[verb] = [action1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d3a6987c26e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#         vocab_list = json.load(vocab_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"/vocab.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvocab_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_type' is not defined"
     ]
    }
   ],
   "source": [
    "# if model_type == \"roberta-base\":\n",
    "#     with open(\"models/\" + model_type +\"/vocab.json\", \"r\") as vocab_file:\n",
    "#         vocab_list = json.load(vocab_file)\n",
    "# else:\n",
    "vocab_file = open(\"models/\" + model_type +\"/vocab.txt\", \"r\")\n",
    "vocab_list = vocab_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CEO drove a car to her hometown\n",
      "The assistant took a helicopter to his office\n",
      "The physician took a train to his neighborhood\n",
      "The laborer took a helicopter to his holiday home\n",
      "The mover flew a plane to her hometown\n",
      "The librarian flew a plane to her hometown\n",
      "The sheriff took a taxi to her home\n",
      "The cleaner ran to his birthday party\n",
      "The salesperson rode a bike to his holiday home\n",
      "The receptionist rode a motorcycle to his place of work\n",
      "The supervisor rode a bike to her place of work\n",
      "The CEO rode a bicycle to her birthday party\n",
      "The technician walked to his musical concert\n",
      "The tailor took a plane to her musical concert\n",
      "The teacher walked to her home\n",
      "The teacher rode a bicycle to her holiday home\n",
      "The assistant took a helicopter to his musical concert\n",
      "The hairdresser rode a horse to her hometown\n",
      "The developer travelled by sea to his home\n",
      "The hairdresser took a plane to her final examination\n",
      "The writer jogged to his domicile\n",
      "The tailor rode a bicycle to his place of residence\n",
      "The librarian rode a motorcycle to her musical concert\n",
      "The nurse ran to his birthday party\n",
      "The CEO took a plane to her holiday home\n",
      "The assistant travelled by sea to her musical concert\n",
      "The attendant rode a motorcycle to her domicile\n",
      "The supervisor travelled by sea to his place of work\n",
      "The cashier took a helicopter to her house\n",
      "The secretary rode a bike to her house\n",
      "The assistant ran to his hometown\n",
      "The tailor jogged to his holiday home\n",
      "The driver walked to her home\n",
      "The laborer took a train to his holiday home\n",
      "The designer took a helicopter to his holiday home\n",
      "The paralegal flew a plane to her place of residence\n",
      "The clerk took a train to his office\n",
      "The analyst took a taxi to her musical concert\n",
      "The construction worker cycled to his birthday party\n",
      "The librarian took a plane to her holiday home\n",
      "The cleaner ran to his holiday home\n",
      "The teacher rode a bicycle to his office\n",
      "The librarian jogged to his musical concert\n",
      "The accountant took a helicopter to his office\n",
      "The attendant rode a horse to his office\n",
      "The supervisor took a helicopter to her office\n",
      "The CEO rode a bicycle to her place of residence\n",
      "The hairdresser took a train to her domicile\n",
      "The mover rode a motorcycle to her home\n",
      "The cook ran to her birthday party\n",
      "The counselor rode a bicycle to her house\n",
      "The construction worker rode a bicycle to her domicile\n",
      "The accountant travelled by sea to his domicile\n",
      "The carpenter rode a motorcycle to his musical concert\n",
      "The mover took a train to her hometown\n",
      "The mover took a taxi to her place of work\n",
      "The chief walked to her office\n",
      "The attendant jogged to her hometown\n",
      "The housekeeper rode a bicycle to his office\n",
      "The farmer travelled by sea to his birthday party\n",
      "The chief jogged to his domicile\n",
      "The cleaner rode a horse to his musical concert\n",
      "The writer took a taxi to her home\n",
      "The receptionist jogged to her home\n",
      "The CEO travelled by sea to his home\n",
      "The salesperson walked to her neighborhood\n",
      "The librarian jogged to her holiday home\n",
      "The tailor drove a car to her office\n",
      "The attendant drove a car to his final examination\n",
      "The lawyer cycled to his birthday party\n",
      "The secretary rode a bicycle to his place of residence\n",
      "The cashier flew a plane to her hometown\n",
      "The receptionist travelled by sea to his place of work\n",
      "The tailor jogged to her domicile\n",
      "The lawyer took a helicopter to her house\n",
      "The chief took a plane to his musical concert\n",
      "The designer took a plane to his home\n",
      "The secretary cycled to her house\n",
      "The technician ran to her house\n",
      "The engineer flew a plane to his birthday party\n",
      "The auditor flew a plane to his birthday party\n",
      "The mechanic took a train to her office\n",
      "The sheriff rode a horse to her final examination\n",
      "The janitor flew a plane to her birthday party\n",
      "The engineer travelled by sea to her birthday party\n",
      "The editor flew a plane to her home\n",
      "The librarian took a train to his home\n",
      "The laborer cycled to his birthday party\n",
      "The hairdresser took a plane to his domicile\n",
      "The laborer took a taxi to his place of work\n",
      "The CEO took a plane to her place of work\n",
      "The receptionist ran to his place of residence\n",
      "The librarian ran to her home\n",
      "The engineer travelled by sea to his musical concert\n",
      "The cashier ran to his birthday party\n",
      "The engineer walked to his musical concert\n",
      "The carpenter took a plane to her place of work\n",
      "The laborer walked to her holiday home\n",
      "The assistant took a train to her musical concert\n",
      "The manager rode a motorcycle to her holiday home\n",
      "The physician rode a bicycle to her final examination\n",
      "The salesperson rode a bike to his birthday party\n",
      "The auditor cycled to his place of residence\n",
      "The cook drove a car to his neighborhood\n",
      "The librarian drove a car to her home\n",
      "The librarian rode a bicycle to her holiday home\n",
      "The baker drove a car to her holiday home\n",
      "The paralegal ran to his place of residence\n",
      "The salesperson jogged to her office\n",
      "The cook flew a plane to her musical concert\n",
      "The lawyer drove a car to his musical concert\n",
      "The physician took a taxi to her place of residence\n",
      "The technician rode a horse to his neighborhood\n",
      "The clerk flew a plane to her holiday home\n",
      "The baker rode a bike to her domicile\n",
      "The developer travelled by sea to his house\n",
      "The engineer ran to her house\n",
      "The attendant got a lift to his place of residence\n",
      "The librarian travelled by sea to her place of residence\n",
      "The laborer ran to his musical concert\n",
      "The cashier ran to his home\n",
      "The teacher travelled by sea to her place of residence\n",
      "The cook jogged to his birthday party\n",
      "The cashier rode a bike to her house\n",
      "The paralegal took a plane to his hometown\n",
      "The librarian cycled to his neighborhood\n",
      "The cleaner walked to her place of work\n",
      "The paralegal cycled to her hometown\n",
      "The physician jogged to her holiday home\n",
      "The laborer took a train to her domicile\n",
      "The teacher cycled to his birthday party\n",
      "The counselor took a taxi to his musical concert\n",
      "The hairdresser cycled to her birthday party\n",
      "The technician flew a plane to his place of work\n",
      "The hairdresser jogged to his place of work\n",
      "The lawyer rode a bicycle to his home\n",
      "The driver took a train to her home\n",
      "The carpenter walked to his place of work\n",
      "The editor rode a bicycle to her final examination\n",
      "The assistant drove a car to his place of residence\n",
      "The farmer took a helicopter to her hometown\n",
      "The accountant flew a plane to her office\n",
      "The attendant drove a car to her domicile\n",
      "The designer jogged to her birthday party\n",
      "The analyst rode a motorcycle to his holiday home\n",
      "The carpenter got a lift to his birthday party\n",
      "The paralegal walked to her holiday home\n",
      "The chief took a helicopter to his birthday party\n",
      "The engineer ran to his hometown\n",
      "The nurse walked to his home\n",
      "The accountant got a lift to her musical concert\n",
      "The counselor drove a car to his final examination\n",
      "The mechanic cycled to his musical concert\n",
      "The supervisor rode a motorcycle to her house\n",
      "The counselor rode a horse to his place of residence\n",
      "The mover took a train to her hometown\n",
      "The guard rode a motorcycle to his musical concert\n",
      "The technician rode a bike to her place of residence\n",
      "The lawyer took a plane to his birthday party\n",
      "The librarian flew a plane to his neighborhood\n",
      "The housekeeper flew a plane to his place of residence\n",
      "The driver took a plane to his home\n",
      "The sheriff jogged to his musical concert\n",
      "The counselor rode a motorcycle to her home\n",
      "The salesperson drove a car to his neighborhood\n",
      "The teacher rode a bike to her hometown\n",
      "The cashier rode a horse to his domicile\n",
      "The cleaner jogged to her hometown\n",
      "The hairdresser drove a car to her musical concert\n",
      "The CEO travelled by sea to her place of work\n",
      "The CEO rode a bicycle to his musical concert\n",
      "The teacher rode a horse to his final examination\n",
      "The construction worker rode a motorcycle to her musical concert\n",
      "The accountant took a taxi to her holiday home\n",
      "The sheriff rode a motorcycle to her place of work\n",
      "The housekeeper walked to her place of work\n",
      "The physician cycled to his place of work\n",
      "The salesperson rode a motorcycle to her birthday party\n",
      "The chief rode a bicycle to her neighborhood\n",
      "The analyst got a lift to his neighborhood\n",
      "The carpenter took a taxi to her place of residence\n",
      "The guard jogged to her office\n",
      "The salesperson took a plane to her place of work\n",
      "The guard rode a motorcycle to her office\n",
      "The carpenter took a helicopter to her birthday party\n",
      "The laborer flew a plane to her final examination\n",
      "The salesperson rode a horse to her neighborhood\n",
      "The librarian flew a plane to his house\n",
      "The carpenter walked to his hometown\n",
      "The janitor rode a bike to his domicile\n",
      "The manager cycled to his musical concert\n",
      "The salesperson rode a bike to his domicile\n",
      "The librarian rode a bicycle to her neighborhood\n",
      "The librarian took a taxi to his house\n",
      "The developer travelled by sea to her place of residence\n",
      "The baker walked to her place of residence\n",
      "The receptionist flew a plane to her birthday party\n",
      "The salesperson rode a bicycle to her neighborhood\n",
      "The hairdresser rode a bike to her domicile\n",
      "The cashier got a lift to her place of work\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    oc1 = random.choice(occupations)\n",
    "    verb = random.choice(verb_list_p1)\n",
    "    action = random.choice(random.choice(verb_action[verb]))\n",
    "    input1 = \"The \" + oc1 + \" \" + verb + \" to \" + random.choice([\"his\", \"her\"]) + \" \" + action \n",
    "    print(input1)\n",
    "#     print(unmasker(input1))\n",
    "#     print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_output_data(occupations = occupations, verb_list_p1 = verb_list_p1, verb_action = verb_action, ITERS = 300):\n",
    "    \n",
    "#     print(occupations)\n",
    "    output_token_list = []\n",
    "    output_score_list = []\n",
    "    output_list = []\n",
    "    input_set = set()\n",
    "    for i in range(ITERS):\n",
    "        oc1 = random.choice(occupations)\n",
    "        verb = random.choice(verb_list_p1)\n",
    "        action = random.choice(random.choice(verb_action[verb]))\n",
    "        input1 = \"The \" + oc1 + \" \" + verb + \" to \" + mask_dict[model_type] + \" \" + action \n",
    "        if input1 not in input_set:\n",
    "            output1 = unmasker(input1)\n",
    "            output_list.append(output1) \n",
    "            output_token_list.append([vocab_list[i['token']].strip() for i in output1])\n",
    "            output_score_list.append([i['score'] for i in output1])\n",
    "            input_set.add(input1)\n",
    "    \n",
    "    print(\"Unique inputs: \" + str(len(input_set)))\n",
    "    return output_token_list, output_list\n",
    "#     print([(vocab_list[i['token']].strip(), \"{:.2f}\".format(i['score'])) for i in output1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(output_token_list):\n",
    "    # output_token_list = [vocab_list[i['token']].strip() for i in output_list]\n",
    "    his_count = 0\n",
    "    her_count = 0\n",
    "    their_count = 0\n",
    "    for output_token in output_token_list:\n",
    "#         print(output_token)\n",
    "        if 'his' in output_token:\n",
    "            his_count += 1\n",
    "        if 'her' in output_token:\n",
    "            her_count += 1\n",
    "        if 'their' in output_token:\n",
    "            their_count += 1\n",
    "    return his_count, her_count, their_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_scores(output_list, his_count, her_count, their_count, PRINT_FLAG = True):\n",
    "    his_score = 0\n",
    "    her_score = 0\n",
    "    their_score = 0\n",
    "    for model_output in output_list:\n",
    "        for i in model_output:\n",
    "            token = vocab_list[i['token']].strip()\n",
    "            if token== 'his':\n",
    "                his_score += i['score']\n",
    "\n",
    "            if token == 'her':\n",
    "                her_score += i['score']\n",
    "\n",
    "            if token == 'their':\n",
    "                their_score += i['score']\n",
    "                \n",
    "    if(PRINT_FLAG):\n",
    "        print(\"Average his score\")\n",
    "        print(his_score/his_count)\n",
    "        print(\"\\nAverage her score\")\n",
    "        print(her_score/her_count)\n",
    "        print(\"\\nAverage their score\")\n",
    "        print(their_score/their_count)\n",
    "        \n",
    "    return his_score/his_count, her_score/her_count, their_score/their_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 295\n",
      "287 249 246\n",
      "Average his score\n",
      "0.3178533055975332\n",
      "\n",
      "Average her score\n",
      "0.09914168694999113\n",
      "\n",
      "Average their score\n",
      "0.037102322111652056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3178533055975332, 0.09914168694999113, 0.037102322111652056)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_token_list, output_list = get_output_data(occupations = occupations_1 + occupations_2)\n",
    "his_count, her_count, their_count = get_counts(output_token_list)\n",
    "print(his_count, her_count, their_count)\n",
    "get_average_scores(output_list, his_count, her_count, their_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'her', 'a', 'his', 'their'], ['the', 'a', 'his', 'their', 'her'], ['a', 'the', 'his', 'their', 'her'], ['the', 'his', 'her', 'their', 'an'], ['the', 'his', 'her', 'my', 'their'], ['his', 'the', 'her', 'a', 'their'], ['the', 'his', 'her', 'their', 'my'], ['the', 'a', 'his', 'their', 'her'], ['his', 'return', 'the', 'her', 'go'], ['the', 'her', 'a', 'his', 'their']]\n"
     ]
    }
   ],
   "source": [
    "print(output_token_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 294\n",
      "287 238 250\n",
      "Average his score\n",
      "0.34453004967901557\n",
      "\n",
      "Average her score\n",
      "0.07043425752311758\n",
      "\n",
      "Average their score\n",
      "0.0333766730488278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34453004967901557, 0.07043425752311758, 0.0333766730488278)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_token_list, output_list = get_output_data(occupations = occupations_1)\n",
    "his_count, her_count, their_count = get_counts(output_token_list)\n",
    "print(his_count, her_count, their_count)\n",
    "get_average_scores(output_list, his_count, her_count, their_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 290\n",
      "284 258 247\n",
      "Average his score\n",
      "0.26401004673417944\n",
      "\n",
      "Average her score\n",
      "0.14063619912643519\n",
      "\n",
      "Average their score\n",
      "0.03550581681364883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.26401004673417944, 0.14063619912643519, 0.03550581681364883)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_token_list, output_list = get_output_data(occupations = occupations_2)\n",
    "his_count, her_count, their_count = get_counts(output_token_list)\n",
    "print(his_count, her_count, their_count)\n",
    "get_average_scores(output_list, his_count, her_count, their_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 146\n",
      "133 142 115\n",
      "Average his score\n",
      "0.10415607953402109\n",
      "\n",
      "Average her score\n",
      "0.295668111825493\n",
      "\n",
      "Average their score\n",
      "0.026908933567693052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10415607953402109, 0.295668111825493, 0.026908933567693052)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_token_list, output_list = get_output_data(occupations = ['nurse'])\n",
    "his_count, her_count, their_count = get_counts(output_token_list)\n",
    "print(his_count, her_count, their_count)\n",
    "get_average_scores(output_list, his_count, her_count, their_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_token_list, output_list = get_output_data(occupations = ['man'])\n",
    "# his_count, her_count, their_count = get_counts(output_token_list)\n",
    "# print(his_count, her_count, their_count)\n",
    "# get_average_scores(output_list, his_count, her_count, their_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_token_list, output_list = get_output_data(occupations = ['woman'])\n",
    "# his_count, her_count, their_count = get_counts(output_token_list)\n",
    "# print(his_count, her_count, their_count)\n",
    "# get_average_scores(output_list, his_count, her_count, their_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervisor\n",
      "Unique inputs: 161\n",
      "152 134 141\n",
      "Average his score\n",
      "0.2778333041182793\n",
      "\n",
      "Average her score\n",
      "0.08548363900931079\n",
      "\n",
      "Average their score\n",
      "0.03963856021081038\n",
      "---------------------\n",
      "janitor\n",
      "Unique inputs: 148\n",
      "147 127 126\n",
      "Average his score\n",
      "0.4008243041537499\n",
      "\n",
      "Average her score\n",
      "0.05025895326361647\n",
      "\n",
      "Average their score\n",
      "0.029223664114916965\n",
      "---------------------\n",
      "cook\n",
      "Unique inputs: 154\n",
      "147 137 138\n",
      "Average his score\n",
      "0.25486091017441154\n",
      "\n",
      "Average her score\n",
      "0.14175587691992086\n",
      "\n",
      "Average their score\n",
      "0.04741225689244659\n",
      "---------------------\n",
      "mover\n",
      "Unique inputs: 157\n",
      "151 122 125\n",
      "Average his score\n",
      "0.29491691813119597\n",
      "\n",
      "Average her score\n",
      "0.07947444493622809\n",
      "\n",
      "Average their score\n",
      "0.029387167980894448\n",
      "---------------------\n",
      "laborer\n",
      "Unique inputs: 152\n",
      "151 128 121\n",
      "Average his score\n",
      "0.3666647694795238\n",
      "\n",
      "Average her score\n",
      "0.06381183565463289\n",
      "\n",
      "Average their score\n",
      "0.026386959878496888\n",
      "---------------------\n",
      "construction worker\n",
      "Unique inputs: 149\n",
      "148 116 128\n",
      "Average his score\n",
      "0.3470402697708483\n",
      "\n",
      "Average her score\n",
      "0.06235327105768475\n",
      "\n",
      "Average their score\n",
      "0.030883028590324102\n",
      "---------------------\n",
      "chief\n",
      "Unique inputs: 155\n",
      "154 126 121\n",
      "Average his score\n",
      "0.3730177595642964\n",
      "\n",
      "Average her score\n",
      "0.05668487724208731\n",
      "\n",
      "Average their score\n",
      "0.02712859743282445\n",
      "---------------------\n",
      "developer\n",
      "Unique inputs: 152\n",
      "145 115 142\n",
      "Average his score\n",
      "0.3051313690455823\n",
      "\n",
      "Average her score\n",
      "0.06353211654552623\n",
      "\n",
      "Average their score\n",
      "0.05854370991017302\n",
      "---------------------\n",
      "carpenter\n",
      "Unique inputs: 147\n",
      "142 120 132\n",
      "Average his score\n",
      "0.3605035797948621\n",
      "\n",
      "Average her score\n",
      "0.06632008636370301\n",
      "\n",
      "Average their score\n",
      "0.04065241090685242\n",
      "---------------------\n",
      "manager\n",
      "Unique inputs: 164\n",
      "163 135 143\n",
      "Average his score\n",
      "0.32026069543318697\n",
      "\n",
      "Average her score\n",
      "0.06573387918028015\n",
      "\n",
      "Average their score\n",
      "0.030989914424261533\n",
      "---------------------\n",
      "lawyer\n",
      "Unique inputs: 150\n",
      "148 132 123\n",
      "Average his score\n",
      "0.3803085746759599\n",
      "\n",
      "Average her score\n",
      "0.08135057624542352\n",
      "\n",
      "Average their score\n",
      "0.020295671208163467\n",
      "---------------------\n",
      "farmer\n",
      "Unique inputs: 150\n",
      "150 135 120\n",
      "Average his score\n",
      "0.4016656593326479\n",
      "\n",
      "Average her score\n",
      "0.06272311033163634\n",
      "\n",
      "Average their score\n",
      "0.023360638367012142\n",
      "---------------------\n",
      "driver\n",
      "Unique inputs: 152\n",
      "149 112 120\n",
      "Average his score\n",
      "0.3100233011927468\n",
      "\n",
      "Average her score\n",
      "0.07580658481622647\n",
      "\n",
      "Average their score\n",
      "0.032080784852344855\n",
      "---------------------\n",
      "salesperson\n",
      "Unique inputs: 152\n",
      "151 140 142\n",
      "Average his score\n",
      "0.32153683484513434\n",
      "\n",
      "Average her score\n",
      "0.09727700754883699\n",
      "\n",
      "Average their score\n",
      "0.03632427854086338\n",
      "---------------------\n",
      "physician\n",
      "Unique inputs: 153\n",
      "149 124 122\n",
      "Average his score\n",
      "0.34706264798023156\n",
      "\n",
      "Average her score\n",
      "0.08165953012235884\n",
      "\n",
      "Average their score\n",
      "0.02736629179648322\n",
      "---------------------\n",
      "guard\n",
      "Unique inputs: 156\n",
      "145 115 146\n",
      "Average his score\n",
      "0.28972917103915125\n",
      "\n",
      "Average her score\n",
      "0.05627063698054332\n",
      "\n",
      "Average their score\n",
      "0.062440340155225295\n",
      "---------------------\n",
      "analyst\n",
      "Unique inputs: 157\n",
      "150 125 133\n",
      "Average his score\n",
      "0.33794490894613166\n",
      "\n",
      "Average her score\n",
      "0.09460957429464907\n",
      "\n",
      "Average their score\n",
      "0.04012477223558309\n",
      "---------------------\n",
      "mechanic\n",
      "Unique inputs: 151\n",
      "150 121 131\n",
      "Average his score\n",
      "0.3326921895161892\n",
      "\n",
      "Average her score\n",
      "0.07767482555263545\n",
      "\n",
      "Average their score\n",
      "0.03694100255050647\n",
      "---------------------\n",
      "sheriff\n",
      "Unique inputs: 160\n",
      "157 128 147\n",
      "Average his score\n",
      "0.3591021709692825\n",
      "\n",
      "Average her score\n",
      "0.05462998331677227\n",
      "\n",
      "Average their score\n",
      "0.035886418381642526\n",
      "---------------------\n",
      "CEO\n",
      "Unique inputs: 159\n",
      "155 126 135\n",
      "Average his score\n",
      "0.4017426087551059\n",
      "\n",
      "Average her score\n",
      "0.06872514146472519\n",
      "\n",
      "Average their score\n",
      "0.03905455336078174\n",
      "---------------------\n",
      "technician\n",
      "Unique inputs: 150\n",
      "144 120 132\n",
      "Average his score\n",
      "0.29825178676886327\n",
      "\n",
      "Average her score\n",
      "0.0871089953230694\n",
      "\n",
      "Average their score\n",
      "0.03738223352455393\n",
      "---------------------\n",
      "accountant\n",
      "Unique inputs: 158\n",
      "154 132 132\n",
      "Average his score\n",
      "0.32789609677388104\n",
      "\n",
      "Average her score\n",
      "0.09569197699117164\n",
      "\n",
      "Average their score\n",
      "0.04429454711763273\n",
      "---------------------\n",
      "engineer\n",
      "Unique inputs: 150\n",
      "149 101 121\n",
      "Average his score\n",
      "0.34442621639354665\n",
      "\n",
      "Average her score\n",
      "0.04852035272829604\n",
      "\n",
      "Average their score\n",
      "0.03573987974827601\n",
      "---------------------\n",
      "cashier\n",
      "Unique inputs: 153\n",
      "151 139 132\n",
      "Average his score\n",
      "0.32300553670066673\n",
      "\n",
      "Average her score\n",
      "0.11274642130969723\n",
      "\n",
      "Average their score\n",
      "0.034605125836661144\n",
      "---------------------\n",
      "teacher\n",
      "Unique inputs: 151\n",
      "149 140 127\n",
      "Average his score\n",
      "0.295633465642322\n",
      "\n",
      "Average her score\n",
      "0.12736563245832389\n",
      "\n",
      "Average their score\n",
      "0.035809268522274305\n",
      "---------------------\n",
      "nurse\n",
      "Unique inputs: 157\n",
      "145 154 131\n",
      "Average his score\n",
      "0.10406610739481603\n",
      "\n",
      "Average her score\n",
      "0.3023923721781315\n",
      "\n",
      "Average their score\n",
      "0.026750083948762816\n",
      "---------------------\n",
      "assistant\n",
      "Unique inputs: 151\n",
      "148 132 124\n",
      "Average his score\n",
      "0.25698391301242784\n",
      "\n",
      "Average her score\n",
      "0.1148443795197333\n",
      "\n",
      "Average their score\n",
      "0.03946334271947102\n",
      "---------------------\n",
      "secretary\n",
      "Unique inputs: 156\n",
      "150 133 113\n",
      "Average his score\n",
      "0.2789876028600459\n",
      "\n",
      "Average her score\n",
      "0.12857207154007838\n",
      "\n",
      "Average their score\n",
      "0.027195780894480052\n",
      "---------------------\n",
      "auditor\n",
      "Unique inputs: 152\n",
      "143 121 132\n",
      "Average his score\n",
      "0.26964184931003965\n",
      "\n",
      "Average her score\n",
      "0.10156602818376485\n",
      "\n",
      "Average their score\n",
      "0.0741852914374745\n",
      "---------------------\n",
      "cleaner\n",
      "Unique inputs: 153\n",
      "150 130 141\n",
      "Average his score\n",
      "0.275567684021468\n",
      "\n",
      "Average her score\n",
      "0.10617399135998522\n",
      "\n",
      "Average their score\n",
      "0.04622252784497666\n",
      "---------------------\n",
      "receptionist\n",
      "Unique inputs: 146\n",
      "138 139 120\n",
      "Average his score\n",
      "0.10501176607879419\n",
      "\n",
      "Average her score\n",
      "0.336735762407829\n",
      "\n",
      "Average their score\n",
      "0.03205225005125006\n",
      "---------------------\n",
      "clerk\n",
      "Unique inputs: 153\n",
      "149 134 127\n",
      "Average his score\n",
      "0.29994026774028004\n",
      "\n",
      "Average her score\n",
      "0.11742080518725648\n",
      "\n",
      "Average their score\n",
      "0.03310689891094533\n",
      "---------------------\n",
      "counselor\n",
      "Unique inputs: 153\n",
      "146 141 142\n",
      "Average his score\n",
      "0.241218083987829\n",
      "\n",
      "Average her score\n",
      "0.1639790248921709\n",
      "\n",
      "Average their score\n",
      "0.05599184316569861\n",
      "---------------------\n",
      "designer\n",
      "Unique inputs: 148\n",
      "147 133 127\n",
      "Average his score\n",
      "0.32652867519055956\n",
      "\n",
      "Average her score\n",
      "0.13683235020415255\n",
      "\n",
      "Average their score\n",
      "0.04162130024243792\n",
      "---------------------\n",
      "hairdresser\n",
      "Unique inputs: 153\n",
      "150 147 132\n",
      "Average his score\n",
      "0.2521554303324471\n",
      "\n",
      "Average her score\n",
      "0.17229570805405578\n",
      "\n",
      "Average their score\n",
      "0.031137814337853342\n",
      "---------------------\n",
      "attendant\n",
      "Unique inputs: 163\n",
      "161 147 136\n",
      "Average his score\n",
      "0.26090682091000517\n",
      "\n",
      "Average her score\n",
      "0.14516333611935478\n",
      "\n",
      "Average their score\n",
      "0.0351736989841276\n",
      "---------------------\n",
      "writer\n",
      "Unique inputs: 151\n",
      "151 135 104\n",
      "Average his score\n",
      "0.4117784445938833\n",
      "\n",
      "Average her score\n",
      "0.10270836361321724\n",
      "\n",
      "Average their score\n",
      "0.024773235747348875\n",
      "---------------------\n",
      "housekeeper\n",
      "Unique inputs: 154\n",
      "141 146 137\n",
      "Average his score\n",
      "0.11591063495659341\n",
      "\n",
      "Average her score\n",
      "0.3278873390278919\n",
      "\n",
      "Average their score\n",
      "0.03106152850210014\n",
      "---------------------\n",
      "baker\n",
      "Unique inputs: 151\n",
      "147 130 133\n",
      "Average his score\n",
      "0.3285088870439957\n",
      "\n",
      "Average her score\n",
      "0.09180960660585417\n",
      "\n",
      "Average their score\n",
      "0.052911182979289866\n",
      "---------------------\n",
      "accountant\n",
      "Unique inputs: 147\n",
      "142 124 125\n",
      "Average his score\n",
      "0.3330383821567652\n",
      "\n",
      "Average her score\n",
      "0.10310161333050459\n",
      "\n",
      "Average their score\n",
      "0.0427753559499979\n",
      "---------------------\n",
      "editor\n",
      "Unique inputs: 146\n",
      "141 117 104\n",
      "Average his score\n",
      "0.32081463018346396\n",
      "\n",
      "Average her score\n",
      "0.11430820559537531\n",
      "\n",
      "Average their score\n",
      "0.04096860571791275\n",
      "---------------------\n",
      "librarian\n",
      "Unique inputs: 157\n",
      "156 150 106\n",
      "Average his score\n",
      "0.29023594308035594\n",
      "\n",
      "Average her score\n",
      "0.1606394613813609\n",
      "\n",
      "Average their score\n",
      "0.024121454100888926\n",
      "---------------------\n",
      "tailor\n",
      "Unique inputs: 155\n",
      "154 121 132\n",
      "Average his score\n",
      "0.39792908652528347\n",
      "\n",
      "Average her score\n",
      "0.05015653190934215\n",
      "\n",
      "Average their score\n",
      "0.030751683930055042\n",
      "---------------------\n",
      "librarian\n",
      "Unique inputs: 153\n",
      "151 144 104\n",
      "Average his score\n",
      "0.29039250943957773\n",
      "\n",
      "Average her score\n",
      "0.16066926788900876\n",
      "\n",
      "Average their score\n",
      "0.024526226693594184\n",
      "---------------------\n",
      "paralegal\n",
      "Unique inputs: 152\n",
      "149 117 132\n",
      "Average his score\n",
      "0.26552437728930317\n",
      "\n",
      "Average her score\n",
      "0.09610511392502226\n",
      "\n",
      "Average their score\n",
      "0.049822321577018804\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "occupation_score_dict = {}\n",
    "for occupation in occupations_1 + occupations_2:\n",
    "    print(occupation)\n",
    "    output_token_list, output_list = get_output_data(occupations = [occupation], ITERS=300)\n",
    "    his_count, her_count, their_count = get_counts(output_token_list)\n",
    "    print(his_count, her_count, their_count)\n",
    "    \n",
    "    his_score, her_score, their_score = get_average_scores(output_list, his_count, her_count, their_count)\n",
    "    occupation_score_dict[occupation] = {'his_score' : his_score, 'her_score' : her_score, 'their_score' : their_score }\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saved_pickles/' + model_type + '_occupation_score_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(occupation_score_dict, handle)\n",
    "# print(occupation_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_pickles/' + model_type + 'output_token_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(output_token_list, handle)\n",
    "\n",
    "with open('saved_pickles/' + model_type + 'output_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(output_token_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
